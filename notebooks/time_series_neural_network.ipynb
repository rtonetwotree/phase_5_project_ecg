{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8a00172b-9894-4971-a537-441334e1f38d",
      "metadata": {
        "id": "8a00172b-9894-4971-a537-441334e1f38d"
      },
      "source": [
        "## First Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!pip install keras-tuner\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AYlBpR4rLRL",
        "outputId": "7506c64a-048a-488a-c28d-4f6eadddb55a"
      },
      "id": "1AYlBpR4rLRL",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m122.9/129.1 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.1/129.1 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.15.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (23.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras-tuner) (2.31.0)\n",
            "Collecting kt-legacy (from keras-tuner)\n",
            "  Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras-tuner) (2024.2.2)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.4.7 kt-legacy-1.0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPQBOk7Rugm3",
        "outputId": "6174d57e-adee-416a-e851-5f3d63f04ff7"
      },
      "id": "BPQBOk7Rugm3",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "96435299-050b-4010-b57c-cc490b83b705",
      "metadata": {
        "id": "96435299-050b-4010-b57c-cc490b83b705"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "from tensorflow.keras.models import load_model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38da3325-d76d-421e-94d0-0596c6b95d3b",
      "metadata": {
        "id": "38da3325-d76d-421e-94d0-0596c6b95d3b"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "37dbff3e-7b6b-4798-9190-3d0180925068",
      "metadata": {
        "id": "37dbff3e-7b6b-4798-9190-3d0180925068"
      },
      "outputs": [],
      "source": [
        "fazeli_mitbih_train_df = pd.read_csv('/content/drive/MyDrive/mitbih_train.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#fazeli_mitbih_test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/mitbih_test.csv', header=None)"
      ],
      "metadata": {
        "id": "KwjAVYgmE55a"
      },
      "id": "KwjAVYgmE55a",
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "74aed28a-031c-4298-a7f8-3d01d46e93be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74aed28a-031c-4298-a7f8-3d01d46e93be",
        "outputId": "6e2adfe8-1899-4d6d-b7fa-2f630d50eb0a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    72471\n",
              "4.0     6431\n",
              "2.0     5788\n",
              "1.0     2223\n",
              "3.0      641\n",
              "Name: 187, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "column_187 = fazeli_mitbih_train_df.iloc[:, 187]\n",
        "column_187.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3376e4c2-e6a3-41fc-8edd-3580bf98081c",
      "metadata": {
        "id": "3376e4c2-e6a3-41fc-8edd-3580bf98081c"
      },
      "source": [
        "# Bidirectional LSTM Neural Network"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two Layers"
      ],
      "metadata": {
        "id": "pmy-STd3p8yz"
      },
      "id": "pmy-STd3p8yz"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_LSTM_bidirectional():\n",
        "    input_shape = (187, 1)  # input shape based on the dataset\n",
        "    model = Sequential([\n",
        "        # Wrapping the LSTM layer with Bidirectional\n",
        "        Bidirectional(LSTM(units=128, return_sequences=True), input_shape=input_shape),\n",
        "        Dropout(0.1),\n",
        "\n",
        "        # Adding another Bidirectional LSTM layer\n",
        "        Bidirectional(LSTM(units=64, return_sequences=False)),\n",
        "        Dropout(0.1),\n",
        "\n",
        "        # Dense layer\n",
        "        Dense(units=150, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(5, activation='softmax')  # Adjusted for 5 classes\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the bidirectional LSTM model\n",
        "model_LSTM_bidirectional = create_model_LSTM_bidirectional()\n",
        "\n",
        "# Now use model_LSTM_bidirectional for training\n"
      ],
      "metadata": {
        "id": "ANmtVjffkqjD"
      },
      "id": "ANmtVjffkqjD",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fazeli_mitbih_train_df is the DataFrame and the last column is the label\n",
        "X = fazeli_mitbih_train_df.iloc[:, :-1].values\n",
        "y = fazeli_mitbih_train_df.iloc[:, -1].values\n",
        "\n",
        "# Reshape X to fit the LSTM input requirements and convert y to categorical\n",
        "X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "y_categorical = to_categorical(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define callbacks\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_model_LSTM_bidirectional.h5',  # filename to reflect it's the bidirectional LSTM model\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=0.001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Create the bidirectional LSTM model with the best hyperparameters\n",
        "# 'create_model_LSTM_bidirectional()' function is defined and returns the bidirectional LSTM model\n",
        "model_LSTM_bidirectional = create_model_LSTM_bidirectional()\n",
        "\n",
        "# Train the bidirectional LSTM model with the callbacks\n",
        "history_LSTM_bidirectional = model_LSTM_bidirectional.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=100,  # Adjust the number of epochs as necessary\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",
        ")\n",
        "\n",
        "# Evaluation on Test Data\n",
        "test_loss, test_accuracy = model_LSTM_bidirectional.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Predictions and Classification Report\n",
        "y_pred = model_LSTM_bidirectional.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c33e8BatqEJk",
        "outputId": "eaa850c1-b928-44ac-ed30-100397149290"
      },
      "id": "c33e8BatqEJk",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.3420 - accuracy: 0.9116\n",
            "Epoch 1: val_loss improved from inf to 0.18621, saving model to best_model_LSTM_bidirectional.h5\n",
            "2189/2189 [==============================] - 71s 30ms/step - loss: 0.3420 - accuracy: 0.9116 - val_loss: 0.1862 - val_accuracy: 0.9517 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "   5/2189 [..............................] - ETA: 57s - loss: 0.2313 - accuracy: 0.9375"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1773 - accuracy: 0.9522\n",
            "Epoch 2: val_loss improved from 0.18621 to 0.14083, saving model to best_model_LSTM_bidirectional.h5\n",
            "2189/2189 [==============================] - 63s 29ms/step - loss: 0.1773 - accuracy: 0.9522 - val_loss: 0.1408 - val_accuracy: 0.9612 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1396 - accuracy: 0.9618\n",
            "Epoch 3: val_loss improved from 0.14083 to 0.11106, saving model to best_model_LSTM_bidirectional.h5\n",
            "2189/2189 [==============================] - 63s 29ms/step - loss: 0.1396 - accuracy: 0.9618 - val_loss: 0.1111 - val_accuracy: 0.9690 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.1208 - accuracy: 0.9662\n",
            "Epoch 4: val_loss did not improve from 0.11106\n",
            "2189/2189 [==============================] - 63s 29ms/step - loss: 0.1209 - accuracy: 0.9662 - val_loss: 0.1157 - val_accuracy: 0.9647 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1043 - accuracy: 0.9709\n",
            "Epoch 5: val_loss improved from 0.11106 to 0.09103, saving model to best_model_LSTM_bidirectional.h5\n",
            "2189/2189 [==============================] - 62s 28ms/step - loss: 0.1043 - accuracy: 0.9709 - val_loss: 0.0910 - val_accuracy: 0.9756 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.1482 - accuracy: 0.9600\n",
            "Epoch 6: val_loss did not improve from 0.09103\n",
            "2189/2189 [==============================] - 62s 28ms/step - loss: 0.1483 - accuracy: 0.9600 - val_loss: 0.5774 - val_accuracy: 0.8390 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.4375 - accuracy: 0.8791\n",
            "Epoch 7: val_loss did not improve from 0.09103\n",
            "2189/2189 [==============================] - 62s 28ms/step - loss: 0.4374 - accuracy: 0.8791 - val_loss: 0.3733 - val_accuracy: 0.9000 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.3789 - accuracy: 0.8996\n",
            "Epoch 8: val_loss did not improve from 0.09103\n",
            "2189/2189 [==============================] - 62s 28ms/step - loss: 0.3789 - accuracy: 0.8996 - val_loss: 0.3313 - val_accuracy: 0.9102 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.3417 - accuracy: 0.9113\n",
            "Epoch 9: val_loss did not improve from 0.09103\n",
            "2189/2189 [==============================] - 62s 28ms/step - loss: 0.3417 - accuracy: 0.9113 - val_loss: 0.3047 - val_accuracy: 0.9230 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.3130 - accuracy: 0.9200\n",
            "Epoch 10: val_loss did not improve from 0.09103\n",
            "2189/2189 [==============================] - 62s 28ms/step - loss: 0.3131 - accuracy: 0.9200 - val_loss: 0.2739 - val_accuracy: 0.9290 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.2981 - accuracy: 0.9230\n",
            "Epoch 11: val_loss did not improve from 0.09103\n",
            "2189/2189 [==============================] - 62s 28ms/step - loss: 0.2981 - accuracy: 0.9230 - val_loss: 0.2750 - val_accuracy: 0.9256 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.2646 - accuracy: 0.9314\n",
            "Epoch 12: val_loss did not improve from 0.09103\n",
            "2189/2189 [==============================] - 62s 28ms/step - loss: 0.2645 - accuracy: 0.9315 - val_loss: 0.2516 - val_accuracy: 0.9360 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.2285 - accuracy: 0.9384\n",
            "Epoch 13: val_loss did not improve from 0.09103\n",
            "2189/2189 [==============================] - 62s 28ms/step - loss: 0.2285 - accuracy: 0.9384 - val_loss: 0.1806 - val_accuracy: 0.9472 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.9477\n",
            "Epoch 14: val_loss did not improve from 0.09103\n",
            "2189/2189 [==============================] - 62s 28ms/step - loss: 0.1886 - accuracy: 0.9477 - val_loss: 0.1506 - val_accuracy: 0.9551 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.1616 - accuracy: 0.9550Restoring model weights from the end of the best epoch: 5.\n",
            "\n",
            "Epoch 15: val_loss did not improve from 0.09103\n",
            "2189/2189 [==============================] - 62s 28ms/step - loss: 0.1616 - accuracy: 0.9550 - val_loss: 0.1448 - val_accuracy: 0.9609 - lr: 0.0010\n",
            "Epoch 15: early stopping\n",
            "548/548 - 6s - loss: 0.0910 - accuracy: 0.9756 - 6s/epoch - 11ms/step\n",
            "Test Loss: 0.09103474020957947\n",
            "Test Accuracy: 0.9756153225898743\n",
            "548/548 [==============================] - 7s 10ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99     14579\n",
            "           1       0.92      0.67      0.78       426\n",
            "           2       0.94      0.89      0.92      1112\n",
            "           3       0.86      0.67      0.75       145\n",
            "           4       0.97      0.98      0.97      1249\n",
            "\n",
            "    accuracy                           0.98     17511\n",
            "   macro avg       0.93      0.84      0.88     17511\n",
            "weighted avg       0.97      0.98      0.97     17511\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "bidirectionality with another layer"
      ],
      "metadata": {
        "id": "Z4LhiQSg5TDO"
      },
      "id": "Z4LhiQSg5TDO"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_LSTM_bidirectional_2():\n",
        "    input_shape = (187, 1)  # input shape based on the dataset\n",
        "    model = Sequential([\n",
        "        Bidirectional(LSTM(units=128, return_sequences=True), input_shape=input_shape),\n",
        "        Dropout(0.1),\n",
        "\n",
        "        Bidirectional(LSTM(units=64, return_sequences=True)),\n",
        "        Dropout(0.1),\n",
        "\n",
        "        Bidirectional(LSTM(units=32, return_sequences=False)),  # Additional layer\n",
        "        Dropout(0.1),\n",
        "\n",
        "        Dense(units=150, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(5, activation='softmax')  # Adjusted for 5 classes\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the LSTM model with two bidirectional layers\n",
        "model_LSTM_bidirectional_2 = create_model_LSTM_bidirectional_2()\n"
      ],
      "metadata": {
        "id": "ffDZ68ERspXJ"
      },
      "id": "ffDZ68ERspXJ",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fazeli_mitbih_train_df is the DataFrame and the last column is the label\n",
        "X = fazeli_mitbih_train_df.iloc[:, :-1].values\n",
        "y = fazeli_mitbih_train_df.iloc[:, -1].values\n",
        "\n",
        "# Reshape X to fit the LSTM input requirements and convert y to categorical\n",
        "X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "y_categorical = to_categorical(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define callbacks\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_model_LSTM_bidirectional_2.h5',  # Updated filename for the new bidirectional model\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=0.001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 'create_model_LSTM_bidirectional_2()' function is defined and returns the bidirectional LSTM model\n",
        "model_LSTM_bidirectional_2 = create_model_LSTM_bidirectional_2()\n",
        "\n",
        "# Train the bidirectional LSTM model with the callbacks\n",
        "history_LSTM_bidirectional_2 = model_LSTM_bidirectional_2.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=100,  # Adjust the number of epochs as necessary\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",
        ")\n",
        "\n",
        "# Evaluation on Test Data\n",
        "test_loss, test_accuracy = model_LSTM_bidirectional_2.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Predictions and Classification Report\n",
        "y_pred = model_LSTM_bidirectional_2.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "vk8wSUZL5av-",
        "outputId": "3af31476-2c85-4401-dca5-d632af874ac6"
      },
      "id": "vk8wSUZL5av-",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.4754 - accuracy: 0.8748\n",
            "Epoch 1: val_loss improved from inf to 0.24721, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 103s 43ms/step - loss: 0.4754 - accuracy: 0.8748 - val_loss: 0.2472 - val_accuracy: 0.9373 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "   3/2189 [..............................] - ETA: 1:21 - loss: 0.2075 - accuracy: 0.9479"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2189/2189 [==============================] - ETA: 0s - loss: 0.2653 - accuracy: 0.9314\n",
            "Epoch 2: val_loss did not improve from 0.24721\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.2653 - accuracy: 0.9314 - val_loss: 0.3246 - val_accuracy: 0.9130 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1852 - accuracy: 0.9490\n",
            "Epoch 3: val_loss improved from 0.24721 to 0.13139, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.1852 - accuracy: 0.9490 - val_loss: 0.1314 - val_accuracy: 0.9620 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1505 - accuracy: 0.9572\n",
            "Epoch 4: val_loss improved from 0.13139 to 0.11245, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 89s 41ms/step - loss: 0.1505 - accuracy: 0.9572 - val_loss: 0.1125 - val_accuracy: 0.9684 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1284 - accuracy: 0.9645\n",
            "Epoch 5: val_loss improved from 0.11245 to 0.11102, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.1284 - accuracy: 0.9645 - val_loss: 0.1110 - val_accuracy: 0.9685 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1184 - accuracy: 0.9672\n",
            "Epoch 6: val_loss improved from 0.11102 to 0.09606, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.1184 - accuracy: 0.9672 - val_loss: 0.0961 - val_accuracy: 0.9730 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1073 - accuracy: 0.9703\n",
            "Epoch 7: val_loss did not improve from 0.09606\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.1073 - accuracy: 0.9703 - val_loss: 0.1004 - val_accuracy: 0.9716 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1001 - accuracy: 0.9721\n",
            "Epoch 8: val_loss improved from 0.09606 to 0.08442, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.1001 - accuracy: 0.9721 - val_loss: 0.0844 - val_accuracy: 0.9765 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0921 - accuracy: 0.9742\n",
            "Epoch 9: val_loss improved from 0.08442 to 0.07346, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.0921 - accuracy: 0.9742 - val_loss: 0.0735 - val_accuracy: 0.9785 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0861 - accuracy: 0.9766\n",
            "Epoch 10: val_loss did not improve from 0.07346\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.0861 - accuracy: 0.9766 - val_loss: 0.0744 - val_accuracy: 0.9782 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0806 - accuracy: 0.9773\n",
            "Epoch 11: val_loss improved from 0.07346 to 0.06918, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.0806 - accuracy: 0.9773 - val_loss: 0.0692 - val_accuracy: 0.9806 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0888 - accuracy: 0.9752\n",
            "Epoch 12: val_loss did not improve from 0.06918\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.0888 - accuracy: 0.9752 - val_loss: 0.0784 - val_accuracy: 0.9781 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0810 - accuracy: 0.9775\n",
            "Epoch 13: val_loss did not improve from 0.06918\n",
            "2189/2189 [==============================] - 91s 41ms/step - loss: 0.0810 - accuracy: 0.9775 - val_loss: 0.0705 - val_accuracy: 0.9793 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0710 - accuracy: 0.9795\n",
            "Epoch 14: val_loss improved from 0.06918 to 0.06808, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.0710 - accuracy: 0.9795 - val_loss: 0.0681 - val_accuracy: 0.9798 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0671 - accuracy: 0.9809\n",
            "Epoch 15: val_loss improved from 0.06808 to 0.06598, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.0671 - accuracy: 0.9809 - val_loss: 0.0660 - val_accuracy: 0.9814 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0646 - accuracy: 0.9809\n",
            "Epoch 16: val_loss improved from 0.06598 to 0.06040, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 95s 43ms/step - loss: 0.0646 - accuracy: 0.9809 - val_loss: 0.0604 - val_accuracy: 0.9828 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0613 - accuracy: 0.9824\n",
            "Epoch 17: val_loss did not improve from 0.06040\n",
            "2189/2189 [==============================] - 95s 43ms/step - loss: 0.0613 - accuracy: 0.9824 - val_loss: 0.0607 - val_accuracy: 0.9832 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0604 - accuracy: 0.9823\n",
            "Epoch 18: val_loss improved from 0.06040 to 0.05732, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 95s 43ms/step - loss: 0.0604 - accuracy: 0.9823 - val_loss: 0.0573 - val_accuracy: 0.9834 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0578 - accuracy: 0.9831\n",
            "Epoch 19: val_loss did not improve from 0.05732\n",
            "2189/2189 [==============================] - 95s 43ms/step - loss: 0.0578 - accuracy: 0.9831 - val_loss: 0.0599 - val_accuracy: 0.9830 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0545 - accuracy: 0.9840\n",
            "Epoch 20: val_loss improved from 0.05732 to 0.05629, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 95s 43ms/step - loss: 0.0545 - accuracy: 0.9840 - val_loss: 0.0563 - val_accuracy: 0.9848 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0530 - accuracy: 0.9849\n",
            "Epoch 21: val_loss did not improve from 0.05629\n",
            "2189/2189 [==============================] - 95s 43ms/step - loss: 0.0530 - accuracy: 0.9849 - val_loss: 0.0631 - val_accuracy: 0.9824 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0520 - accuracy: 0.9844\n",
            "Epoch 22: val_loss improved from 0.05629 to 0.05616, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 95s 43ms/step - loss: 0.0520 - accuracy: 0.9844 - val_loss: 0.0562 - val_accuracy: 0.9845 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0498 - accuracy: 0.9853\n",
            "Epoch 23: val_loss did not improve from 0.05616\n",
            "2189/2189 [==============================] - 95s 43ms/step - loss: 0.0498 - accuracy: 0.9853 - val_loss: 0.0564 - val_accuracy: 0.9851 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0471 - accuracy: 0.9859\n",
            "Epoch 24: val_loss improved from 0.05616 to 0.05340, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 94s 43ms/step - loss: 0.0471 - accuracy: 0.9859 - val_loss: 0.0534 - val_accuracy: 0.9850 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0467 - accuracy: 0.9867\n",
            "Epoch 25: val_loss improved from 0.05340 to 0.05186, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 95s 43ms/step - loss: 0.0467 - accuracy: 0.9867 - val_loss: 0.0519 - val_accuracy: 0.9854 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0448 - accuracy: 0.9866\n",
            "Epoch 26: val_loss did not improve from 0.05186\n",
            "2189/2189 [==============================] - 94s 43ms/step - loss: 0.0448 - accuracy: 0.9866 - val_loss: 0.0569 - val_accuracy: 0.9840 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0440 - accuracy: 0.9870\n",
            "Epoch 27: val_loss did not improve from 0.05186\n",
            "2189/2189 [==============================] - 91s 42ms/step - loss: 0.0440 - accuracy: 0.9870 - val_loss: 0.0652 - val_accuracy: 0.9843 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0419 - accuracy: 0.9874\n",
            "Epoch 28: val_loss did not improve from 0.05186\n",
            "2189/2189 [==============================] - 91s 41ms/step - loss: 0.0419 - accuracy: 0.9874 - val_loss: 0.0590 - val_accuracy: 0.9850 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0416 - accuracy: 0.9878\n",
            "Epoch 29: val_loss did not improve from 0.05186\n",
            "2189/2189 [==============================] - 91s 41ms/step - loss: 0.0416 - accuracy: 0.9878 - val_loss: 0.0544 - val_accuracy: 0.9862 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.0409 - accuracy: 0.9876\n",
            "Epoch 30: val_loss did not improve from 0.05186\n",
            "2189/2189 [==============================] - 91s 42ms/step - loss: 0.0409 - accuracy: 0.9876 - val_loss: 0.0889 - val_accuracy: 0.9732 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0392 - accuracy: 0.9879\n",
            "Epoch 31: val_loss did not improve from 0.05186\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.0392 - accuracy: 0.9879 - val_loss: 0.0563 - val_accuracy: 0.9846 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.0383 - accuracy: 0.9881\n",
            "Epoch 32: val_loss did not improve from 0.05186\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.0383 - accuracy: 0.9881 - val_loss: 0.0591 - val_accuracy: 0.9845 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0364 - accuracy: 0.9886\n",
            "Epoch 33: val_loss did not improve from 0.05186\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.0364 - accuracy: 0.9886 - val_loss: 0.0522 - val_accuracy: 0.9866 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.0374 - accuracy: 0.9880\n",
            "Epoch 34: val_loss did not improve from 0.05186\n",
            "2189/2189 [==============================] - 91s 42ms/step - loss: 0.0374 - accuracy: 0.9880 - val_loss: 0.0606 - val_accuracy: 0.9855 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0363 - accuracy: 0.9889\n",
            "Epoch 35: val_loss improved from 0.05186 to 0.04646, saving model to best_model_LSTM_bidirectional_2.h5\n",
            "2189/2189 [==============================] - 89s 40ms/step - loss: 0.0363 - accuracy: 0.9889 - val_loss: 0.0465 - val_accuracy: 0.9863 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.0373 - accuracy: 0.9885\n",
            "Epoch 36: val_loss did not improve from 0.04646\n",
            "2189/2189 [==============================] - 90s 41ms/step - loss: 0.0373 - accuracy: 0.9885 - val_loss: 0.0519 - val_accuracy: 0.9870 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0338 - accuracy: 0.9895\n",
            "Epoch 37: val_loss did not improve from 0.04646\n",
            "2189/2189 [==============================] - 88s 40ms/step - loss: 0.0338 - accuracy: 0.9895 - val_loss: 0.0568 - val_accuracy: 0.9848 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0328 - accuracy: 0.9898\n",
            "Epoch 38: val_loss did not improve from 0.04646\n",
            "2189/2189 [==============================] - 89s 40ms/step - loss: 0.0328 - accuracy: 0.9898 - val_loss: 0.0492 - val_accuracy: 0.9862 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0331 - accuracy: 0.9896\n",
            "Epoch 39: val_loss did not improve from 0.04646\n",
            "2189/2189 [==============================] - 89s 41ms/step - loss: 0.0331 - accuracy: 0.9896 - val_loss: 0.0515 - val_accuracy: 0.9861 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0317 - accuracy: 0.9897\n",
            "Epoch 40: val_loss did not improve from 0.04646\n",
            "2189/2189 [==============================] - 89s 41ms/step - loss: 0.0317 - accuracy: 0.9897 - val_loss: 0.0507 - val_accuracy: 0.9867 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0310 - accuracy: 0.9898\n",
            "Epoch 41: val_loss did not improve from 0.04646\n",
            "2189/2189 [==============================] - 88s 40ms/step - loss: 0.0310 - accuracy: 0.9898 - val_loss: 0.0526 - val_accuracy: 0.9861 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0314 - accuracy: 0.9900\n",
            "Epoch 42: val_loss did not improve from 0.04646\n",
            "2189/2189 [==============================] - 88s 40ms/step - loss: 0.0314 - accuracy: 0.9900 - val_loss: 0.0538 - val_accuracy: 0.9857 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0312 - accuracy: 0.9898\n",
            "Epoch 43: val_loss did not improve from 0.04646\n",
            "2189/2189 [==============================] - 89s 41ms/step - loss: 0.0312 - accuracy: 0.9898 - val_loss: 0.0499 - val_accuracy: 0.9863 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9913\n",
            "Epoch 44: val_loss did not improve from 0.04646\n",
            "2189/2189 [==============================] - 88s 40ms/step - loss: 0.0274 - accuracy: 0.9913 - val_loss: 0.0557 - val_accuracy: 0.9877 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9905Restoring model weights from the end of the best epoch: 35.\n",
            "\n",
            "Epoch 45: val_loss did not improve from 0.04646\n",
            "2189/2189 [==============================] - 89s 41ms/step - loss: 0.0293 - accuracy: 0.9905 - val_loss: 0.0542 - val_accuracy: 0.9871 - lr: 0.0010\n",
            "Epoch 45: early stopping\n",
            "548/548 - 8s - loss: 0.0465 - accuracy: 0.9863 - 8s/epoch - 15ms/step\n",
            "Test Loss: 0.04645908623933792\n",
            "Test Accuracy: 0.9862943291664124\n",
            "548/548 [==============================] - 10s 15ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99     14579\n",
            "           1       0.92      0.78      0.84       426\n",
            "           2       0.97      0.96      0.96      1112\n",
            "           3       0.88      0.82      0.85       145\n",
            "           4       0.99      0.99      0.99      1249\n",
            "\n",
            "    accuracy                           0.99     17511\n",
            "   macro avg       0.95      0.91      0.93     17511\n",
            "weighted avg       0.99      0.99      0.99     17511\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hyperparamater Tuning a 2 layer Bidirectional LSTM model"
      ],
      "metadata": {
        "id": "j7jgzQNeyEvC"
      },
      "id": "j7jgzQNeyEvC"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner import HyperModel, Hyperband\n",
        "\n",
        "class LSTMHyperModel(HyperModel):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def build(self, hp):\n",
        "        model = Sequential()\n",
        "        model.add(Bidirectional(LSTM(units=hp.Int('units_1', min_value=32, max_value=128, step=32), return_sequences=True), input_shape=self.input_shape))\n",
        "        model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.0, max_value=0.5, default=0.25, step=0.1)))\n",
        "\n",
        "        # Adding another bidirectional LSTM layer if return_sequences is set to True\n",
        "        model.add(Bidirectional(LSTM(units=hp.Int('units_2', min_value=64, max_value=256, step=32), return_sequences=False)))\n",
        "        model.add(Dropout(rate=hp.Float('dropout_2', min_value=0.0, max_value=0.5, default=0.25, step=0.1)))\n",
        "\n",
        "        model.add(Dense(units=hp.Int('dense_units', min_value=50, max_value=150, step=50), activation='relu'))\n",
        "        model.add(Dropout(rate=hp.Float('dropout_3', min_value=0.0, max_value=0.5, default=0.25, step=0.1)))\n",
        "\n",
        "        model.add(Dense(self.num_classes, activation='softmax'))\n",
        "\n",
        "        model.compile(optimizer=Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "# Load your data\n",
        "X = fazeli_mitbih_train_df.iloc[:, :-1].values\n",
        "y = fazeli_mitbih_train_df.iloc[:, -1].values\n",
        "\n",
        "# Preprocess the data\n",
        "X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "y_categorical = to_categorical(y)\n",
        "num_classes = y_categorical.shape[1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001, verbose=1),\n",
        "    ModelCheckpoint('best_model_LSTM_bidirectional_2.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "]\n",
        "\n",
        "# Instantiate and configure the hypermodel\n",
        "hypermodel = LSTMHyperModel(input_shape=(187, 1), num_classes=num_classes)\n",
        "\n",
        "# Instantiate the tuner\n",
        "tuner = Hyperband(\n",
        "    hypermodel,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    directory='hyperband',\n",
        "    project_name='mitbih_lstm_classification'\n",
        ")\n",
        "\n",
        "# Start the search for the best hyperparameter configuration\n",
        "tuner.search(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=10, callbacks=callbacks)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "94DJb-xN6FVc",
        "outputId": "6d3a124f-7556-4fd0-cb64-9050703a4cd6"
      },
      "id": "94DJb-xN6FVc",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 30 Complete [00h 10m 53s]\n",
            "val_accuracy: 0.9740163087844849\n",
            "\n",
            "Best val_accuracy So Far: 0.9820113182067871\n",
            "Total elapsed time: 02h 18m 46s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Recreate the tuner with the same configuration\n",
        "tuner = Hyperband(\n",
        "    hypermodel,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    directory='hyperband',  # Same directory as before\n",
        "    project_name='mitbih_lstm_classification'  # Same project name as before\n",
        ")\n",
        "\n",
        "# Load the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters()[0]\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\")\n",
        "for hp in best_hps.space:\n",
        "    print(f\"{hp.name}: {best_hps.get(hp.name)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "YUfnFsdWuXkv",
        "outputId": "482c04d5-7207-49b3-9633-68059552cbcd"
      },
      "id": "YUfnFsdWuXkv",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from hyperband/mitbih_lstm_classification/tuner0.json\n",
            "Best Hyperparameters:\n",
            "units_1: 64\n",
            "dropout_1: 0.0\n",
            "units_2: 160\n",
            "dropout_2: 0.4\n",
            "dense_units: 100\n",
            "dropout_3: 0.2\n",
            "learning_rate: 0.002097863337902064\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def create_model_LSTM_bidirectional_2_with_best_hps():\n",
        "    input_shape = (187, 1)  # input shape based on the dataset\n",
        "    model = Sequential([\n",
        "        Bidirectional(LSTM(units=64, return_sequences=True), input_shape=input_shape),  # units_1: 64\n",
        "        Dropout(0.0),  # dropout_1: 0.0\n",
        "\n",
        "        Bidirectional(LSTM(units=160, return_sequences=False)),  # units_2: 160\n",
        "        Dropout(0.4),  # dropout_2: 0.4\n",
        "\n",
        "        Dense(units=100, activation='relu'),  # dense_units: 100\n",
        "        Dropout(0.2),  # dropout_3: 0.2\n",
        "\n",
        "        Dense(5, activation='softmax')  # Assuming 5 classes\n",
        "    ])\n",
        "\n",
        "    # learning_rate: 0.002097863337902064\n",
        "    model.compile(optimizer=Adam(learning_rate=0.002097863337902064), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the LSTM model with best hyperparameters\n",
        "model_LSTM_bidirectional_2_with_best_hps = create_model_LSTM_bidirectional_2_with_best_hps()\n"
      ],
      "metadata": {
        "id": "FcvYmJllrcwG"
      },
      "id": "FcvYmJllrcwG",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fazeli_mitbih_train_df is the DataFrame and the last column is the label\n",
        "X = fazeli_mitbih_train_df.iloc[:, :-1].values\n",
        "y = fazeli_mitbih_train_df.iloc[:, -1].values\n",
        "\n",
        "# Reshape X to fit the LSTM input requirements and convert y to categorical\n",
        "X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "y_categorical = to_categorical(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define callbacks\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_model_LSTM_bidirectional_2_with_best_hps.h5',  # Updated filename for the model with best hyperparameters\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=0.001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Use the model with best hyperparameters created earlier\n",
        "model = model_LSTM_bidirectional_2_with_best_hps  # this model is already created with the function call\n",
        "\n",
        "# Train the model with the callbacks\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=100,  # Adjust the number of epochs as necessary\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",
        ")\n",
        "\n",
        "# Evaluation on Test Data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Predictions and Classification Report\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "jjTxpRu-riSd",
        "outputId": "902f197c-2a17-4a3c-c31b-049f23e6641e"
      },
      "id": "jjTxpRu-riSd",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.3303 - accuracy: 0.9148\n",
            "Epoch 1: val_loss improved from inf to 0.19216, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 76s 31ms/step - loss: 0.3303 - accuracy: 0.9148 - val_loss: 0.1922 - val_accuracy: 0.9460 - lr: 0.0021\n",
            "Epoch 2/100\n",
            "   5/2189 [..............................] - ETA: 1:00 - loss: 0.1781 - accuracy: 0.9563"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1739 - accuracy: 0.9529\n",
            "Epoch 2: val_loss improved from 0.19216 to 0.12433, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 65s 30ms/step - loss: 0.1739 - accuracy: 0.9529 - val_loss: 0.1243 - val_accuracy: 0.9640 - lr: 0.0021\n",
            "Epoch 3/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1412 - accuracy: 0.9607\n",
            "Epoch 3: val_loss improved from 0.12433 to 0.11655, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 66s 30ms/step - loss: 0.1412 - accuracy: 0.9607 - val_loss: 0.1166 - val_accuracy: 0.9648 - lr: 0.0021\n",
            "Epoch 4/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1214 - accuracy: 0.9653\n",
            "Epoch 4: val_loss improved from 0.11655 to 0.09571, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 68s 31ms/step - loss: 0.1214 - accuracy: 0.9653 - val_loss: 0.0957 - val_accuracy: 0.9717 - lr: 0.0021\n",
            "Epoch 5/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1159 - accuracy: 0.9671\n",
            "Epoch 5: val_loss improved from 0.09571 to 0.09117, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 69s 31ms/step - loss: 0.1159 - accuracy: 0.9671 - val_loss: 0.0912 - val_accuracy: 0.9726 - lr: 0.0021\n",
            "Epoch 6/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1030 - accuracy: 0.9708\n",
            "Epoch 6: val_loss did not improve from 0.09117\n",
            "2189/2189 [==============================] - 68s 31ms/step - loss: 0.1030 - accuracy: 0.9708 - val_loss: 0.0965 - val_accuracy: 0.9701 - lr: 0.0021\n",
            "Epoch 7/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0914 - accuracy: 0.9740\n",
            "Epoch 7: val_loss improved from 0.09117 to 0.08135, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 67s 31ms/step - loss: 0.0914 - accuracy: 0.9740 - val_loss: 0.0813 - val_accuracy: 0.9770 - lr: 0.0021\n",
            "Epoch 8/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0854 - accuracy: 0.9755\n",
            "Epoch 8: val_loss improved from 0.08135 to 0.07629, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 67s 31ms/step - loss: 0.0854 - accuracy: 0.9755 - val_loss: 0.0763 - val_accuracy: 0.9780 - lr: 0.0021\n",
            "Epoch 9/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0756 - accuracy: 0.9782\n",
            "Epoch 9: val_loss improved from 0.07629 to 0.07176, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 67s 31ms/step - loss: 0.0756 - accuracy: 0.9782 - val_loss: 0.0718 - val_accuracy: 0.9804 - lr: 0.0021\n",
            "Epoch 10/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9789\n",
            "Epoch 10: val_loss improved from 0.07176 to 0.06772, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 66s 30ms/step - loss: 0.0728 - accuracy: 0.9789 - val_loss: 0.0677 - val_accuracy: 0.9808 - lr: 0.0021\n",
            "Epoch 11/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0754 - accuracy: 0.9779\n",
            "Epoch 11: val_loss improved from 0.06772 to 0.06463, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 66s 30ms/step - loss: 0.0754 - accuracy: 0.9779 - val_loss: 0.0646 - val_accuracy: 0.9819 - lr: 0.0021\n",
            "Epoch 12/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0620 - accuracy: 0.9816\n",
            "Epoch 12: val_loss did not improve from 0.06463\n",
            "2189/2189 [==============================] - 66s 30ms/step - loss: 0.0620 - accuracy: 0.9816 - val_loss: 0.0768 - val_accuracy: 0.9778 - lr: 0.0021\n",
            "Epoch 13/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0593 - accuracy: 0.9824\n",
            "Epoch 13: val_loss improved from 0.06463 to 0.05724, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 66s 30ms/step - loss: 0.0593 - accuracy: 0.9824 - val_loss: 0.0572 - val_accuracy: 0.9841 - lr: 0.0021\n",
            "Epoch 14/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0570 - accuracy: 0.9835\n",
            "Epoch 14: val_loss did not improve from 0.05724\n",
            "2189/2189 [==============================] - 65s 30ms/step - loss: 0.0570 - accuracy: 0.9835 - val_loss: 0.0659 - val_accuracy: 0.9827 - lr: 0.0021\n",
            "Epoch 15/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0630 - accuracy: 0.9821\n",
            "Epoch 15: val_loss did not improve from 0.05724\n",
            "2189/2189 [==============================] - 66s 30ms/step - loss: 0.0630 - accuracy: 0.9821 - val_loss: 0.0596 - val_accuracy: 0.9825 - lr: 0.0021\n",
            "Epoch 16/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0500 - accuracy: 0.9846\n",
            "Epoch 16: val_loss did not improve from 0.05724\n",
            "2189/2189 [==============================] - 65s 30ms/step - loss: 0.0500 - accuracy: 0.9846 - val_loss: 0.0617 - val_accuracy: 0.9840 - lr: 0.0021\n",
            "Epoch 17/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0489 - accuracy: 0.9861\n",
            "Epoch 17: val_loss improved from 0.05724 to 0.05590, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 66s 30ms/step - loss: 0.0489 - accuracy: 0.9861 - val_loss: 0.0559 - val_accuracy: 0.9868 - lr: 0.0021\n",
            "Epoch 18/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0457 - accuracy: 0.9867\n",
            "Epoch 18: val_loss improved from 0.05590 to 0.05268, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 68s 31ms/step - loss: 0.0457 - accuracy: 0.9867 - val_loss: 0.0527 - val_accuracy: 0.9856 - lr: 0.0021\n",
            "Epoch 19/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0456 - accuracy: 0.9865\n",
            "Epoch 19: val_loss improved from 0.05268 to 0.05223, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 68s 31ms/step - loss: 0.0456 - accuracy: 0.9865 - val_loss: 0.0522 - val_accuracy: 0.9865 - lr: 0.0021\n",
            "Epoch 20/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0421 - accuracy: 0.9875\n",
            "Epoch 20: val_loss did not improve from 0.05223\n",
            "2189/2189 [==============================] - 67s 31ms/step - loss: 0.0421 - accuracy: 0.9875 - val_loss: 0.0764 - val_accuracy: 0.9810 - lr: 0.0021\n",
            "Epoch 21/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0404 - accuracy: 0.9878\n",
            "Epoch 21: val_loss improved from 0.05223 to 0.04825, saving model to best_model_LSTM_bidirectional_2_with_best_hps.h5\n",
            "2189/2189 [==============================] - 66s 30ms/step - loss: 0.0404 - accuracy: 0.9878 - val_loss: 0.0482 - val_accuracy: 0.9868 - lr: 0.0021\n",
            "Epoch 22/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0382 - accuracy: 0.9884\n",
            "Epoch 22: val_loss did not improve from 0.04825\n",
            "2189/2189 [==============================] - 65s 30ms/step - loss: 0.0382 - accuracy: 0.9884 - val_loss: 0.0576 - val_accuracy: 0.9851 - lr: 0.0021\n",
            "Epoch 23/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9889\n",
            "Epoch 23: val_loss did not improve from 0.04825\n",
            "2189/2189 [==============================] - 68s 31ms/step - loss: 0.0362 - accuracy: 0.9889 - val_loss: 0.0581 - val_accuracy: 0.9840 - lr: 0.0021\n",
            "Epoch 24/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0362 - accuracy: 0.9892\n",
            "Epoch 24: val_loss did not improve from 0.04825\n",
            "2189/2189 [==============================] - 68s 31ms/step - loss: 0.0362 - accuracy: 0.9892 - val_loss: 0.0582 - val_accuracy: 0.9873 - lr: 0.0021\n",
            "Epoch 25/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9897\n",
            "Epoch 25: val_loss did not improve from 0.04825\n",
            "2189/2189 [==============================] - 66s 30ms/step - loss: 0.0337 - accuracy: 0.9897 - val_loss: 0.0564 - val_accuracy: 0.9862 - lr: 0.0021\n",
            "Epoch 26/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0334 - accuracy: 0.9894\n",
            "Epoch 26: ReduceLROnPlateau reducing learning rate to 0.001.\n",
            "\n",
            "Epoch 26: val_loss did not improve from 0.04825\n",
            "2189/2189 [==============================] - 67s 31ms/step - loss: 0.0334 - accuracy: 0.9894 - val_loss: 0.0530 - val_accuracy: 0.9867 - lr: 0.0021\n",
            "Epoch 27/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0222 - accuracy: 0.9929\n",
            "Epoch 27: val_loss did not improve from 0.04825\n",
            "2189/2189 [==============================] - 67s 31ms/step - loss: 0.0222 - accuracy: 0.9929 - val_loss: 0.0525 - val_accuracy: 0.9882 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0190 - accuracy: 0.9935\n",
            "Epoch 28: val_loss did not improve from 0.04825\n",
            "2189/2189 [==============================] - 68s 31ms/step - loss: 0.0190 - accuracy: 0.9935 - val_loss: 0.0592 - val_accuracy: 0.9887 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9940\n",
            "Epoch 29: val_loss did not improve from 0.04825\n",
            "2189/2189 [==============================] - 68s 31ms/step - loss: 0.0174 - accuracy: 0.9940 - val_loss: 0.0674 - val_accuracy: 0.9885 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0166 - accuracy: 0.9944\n",
            "Epoch 30: val_loss did not improve from 0.04825\n",
            "2189/2189 [==============================] - 67s 31ms/step - loss: 0.0166 - accuracy: 0.9944 - val_loss: 0.0659 - val_accuracy: 0.9881 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0159 - accuracy: 0.9941Restoring model weights from the end of the best epoch: 21.\n",
            "\n",
            "Epoch 31: val_loss did not improve from 0.04825\n",
            "2189/2189 [==============================] - 66s 30ms/step - loss: 0.0159 - accuracy: 0.9941 - val_loss: 0.0696 - val_accuracy: 0.9887 - lr: 0.0010\n",
            "Epoch 31: early stopping\n",
            "548/548 - 6s - loss: 0.0482 - accuracy: 0.9868 - 6s/epoch - 11ms/step\n",
            "Test Loss: 0.0482456311583519\n",
            "Test Accuracy: 0.9867511987686157\n",
            "548/548 [==============================] - 7s 11ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99     14579\n",
            "           1       0.91      0.82      0.86       426\n",
            "           2       0.95      0.97      0.96      1112\n",
            "           3       0.92      0.75      0.83       145\n",
            "           4       0.99      0.99      0.99      1249\n",
            "\n",
            "    accuracy                           0.99     17511\n",
            "   macro avg       0.95      0.90      0.93     17511\n",
            "weighted avg       0.99      0.99      0.99     17511\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Final Model: Hyperparamater tuning a 1-layer bidirectional LTSM\n",
        "\n",
        "it turns out 1 bidirectional LTSM layer performs about as well as a more complex 2- or 3-layered bidirectional LTSM. So go with the simpler model!"
      ],
      "metadata": {
        "id": "VgvRabgraMSR"
      },
      "id": "VgvRabgraMSR"
    },
    {
      "cell_type": "code",
      "source": [
        "from keras_tuner import HyperModel, Hyperband\n",
        "\n",
        "class LSTMHyperModel1Layer(HyperModel):\n",
        "    def __init__(self, input_shape, num_classes):\n",
        "        self.input_shape = input_shape\n",
        "        self.num_classes = num_classes\n",
        "\n",
        "    def build(self, hp):\n",
        "        model = Sequential()\n",
        "        model.add(Bidirectional(LSTM(units=hp.Int('units_1', min_value=32, max_value=128, step=32), return_sequences=False), input_shape=self.input_shape))\n",
        "        model.add(Dropout(rate=hp.Float('dropout_1', min_value=0.0, max_value=0.5, default=0.25, step=0.1)))\n",
        "\n",
        "        model.add(Dense(units=hp.Int('dense_units', min_value=50, max_value=150, step=50), activation='relu'))\n",
        "        model.add(Dropout(rate=hp.Float('dropout_2', min_value=0.0, max_value=0.5, default=0.25, step=0.1)))\n",
        "\n",
        "        model.add(Dense(self.num_classes, activation='softmax'))\n",
        "\n",
        "        model.compile(optimizer=Adam(hp.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='LOG')),\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "        return model\n",
        "\n",
        "\n",
        "# Load your data\n",
        "X = fazeli_mitbih_train_df.iloc[:, :-1].values\n",
        "y = fazeli_mitbih_train_df.iloc[:, -1].values\n",
        "\n",
        "# Preprocess the data\n",
        "X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "y_categorical = to_categorical(y)\n",
        "num_classes = y_categorical.shape[1]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define callbacks\n",
        "callbacks = [\n",
        "    EarlyStopping(monitor='val_loss', patience=10, verbose=1, restore_best_weights=True),\n",
        "    ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_lr=0.001, verbose=1),\n",
        "    ModelCheckpoint('best_model_LSTM_1layer.h5', monitor='val_loss', save_best_only=True, verbose=1)\n",
        "]\n",
        "\n",
        "# Instantiate and configure the hypermodel\n",
        "hypermodel = LSTMHyperModel1Layer(input_shape=(187, 1), num_classes=num_classes)\n",
        "\n",
        "# Instantiate the tuner\n",
        "tuner = Hyperband(\n",
        "    hypermodel,\n",
        "    objective='val_accuracy',\n",
        "    max_epochs=10,\n",
        "    directory='hyperband',\n",
        "    project_name='mitbih_lstm_classification'\n",
        ")\n",
        "\n",
        "# Start the search for the best hyperparameter configuration\n",
        "tuner.search(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=10, callbacks=callbacks)\n"
      ],
      "metadata": {
        "id": "jPaQNKdkaL7L"
      },
      "id": "jPaQNKdkaL7L",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the best hyperparameters\n",
        "best_hps = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "\n",
        "# Print the best hyperparameters\n",
        "print(\"Best Hyperparameters:\")\n",
        "for param in best_hps.values:\n",
        "    print(f\"{param}: {best_hps.get(param)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMawztE1bOvQ",
        "outputId": "a911e3a0-8956-4b1b-dca9-088f58927a7f"
      },
      "id": "IMawztE1bOvQ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters:\n",
            "units_1: 128\n",
            "dropout_1: 0.1\n",
            "dense_units: 100\n",
            "dropout_2: 0.2\n",
            "learning_rate: 0.0007043882704094401\n",
            "tuner/epochs: 10\n",
            "tuner/initial_epoch: 4\n",
            "tuner/bracket: 2\n",
            "tuner/round: 2\n",
            "tuner/trial_id: 0012\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_LSTM_1layer_with_best_hps():\n",
        "    input_shape = (187, 1)\n",
        "    best_units_1 = 128\n",
        "    best_dropout_1 = 0.1\n",
        "    best_dense_units = 100\n",
        "    best_dropout_2 = 0.2\n",
        "    best_learning_rate = 0.0007043882704094401\n",
        "\n",
        "    model = Sequential([\n",
        "        Bidirectional(LSTM(units=best_units_1, return_sequences=False), input_shape=input_shape),\n",
        "        Dropout(best_dropout_1),\n",
        "\n",
        "        Dense(units=best_dense_units, activation='relu'),\n",
        "        Dropout(best_dropout_2),\n",
        "\n",
        "        Dense(5, activation='softmax')  # Assuming 5 classes\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=best_learning_rate), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the LSTM model with best hyperparameters\n",
        "model_LSTM_1layer_with_best_hps = create_model_LSTM_1layer_with_best_hps()\n"
      ],
      "metadata": {
        "id": "q5ZwwwRfuN1e"
      },
      "id": "q5ZwwwRfuN1e",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# fazeli_mitbih_train_df is the DataFrame and the last column is the label\n",
        "X = fazeli_mitbih_train_df.iloc[:, :-1].values\n",
        "y = fazeli_mitbih_train_df.iloc[:, -1].values\n",
        "\n",
        "# Reshape X to fit the LSTM input requirements and convert y to categorical\n",
        "X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "y_categorical = to_categorical(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define callbacks\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_model_LSTM_1layer_with_best_hps.h5',  # Updated filename for the model with best hyperparameters\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,\n",
        "    verbose=1\n",
        ")\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=0.001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# create_model_LSTM_1layer_with_best_hps() is defined as previously shown\n",
        "model_LSTM_1layer_with_best_hps = create_model_LSTM_1layer_with_best_hps()\n",
        "\n",
        "# Train the model with the callbacks\n",
        "history = model_LSTM_1layer_with_best_hps.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=100,\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping, reduce_lr, model_checkpoint]\n",
        ")\n",
        "\n",
        "# Evaluation on Test Data\n",
        "test_loss, test_accuracy = model_LSTM_1layer_with_best_hps.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n",
        "# Predictions and Classification Report\n",
        "y_pred = model_LSTM_1layer_with_best_hps.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true = np.argmax(y_test, axis=1)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_true, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WZtSnpBFvj1-",
        "outputId": "17bbcfde-0d6c-490a-dc0e-ff9586f749fe"
      },
      "id": "WZtSnpBFvj1-",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.3786 - accuracy: 0.8995\n",
            "Epoch 1: val_loss improved from inf to 0.22889, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 38s 16ms/step - loss: 0.3785 - accuracy: 0.8995 - val_loss: 0.2289 - val_accuracy: 0.9419 - lr: 7.0439e-04\n",
            "Epoch 2/100\n",
            "   9/2189 [..............................] - ETA: 30s - loss: 0.1850 - accuracy: 0.9479"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.2287 - accuracy: 0.9407\n",
            "Epoch 2: val_loss improved from 0.22889 to 0.20034, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.2287 - accuracy: 0.9407 - val_loss: 0.2003 - val_accuracy: 0.9446 - lr: 7.0439e-04\n",
            "Epoch 3/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1935 - accuracy: 0.9499\n",
            "Epoch 3: val_loss improved from 0.20034 to 0.17011, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.1935 - accuracy: 0.9499 - val_loss: 0.1701 - val_accuracy: 0.9512 - lr: 7.0439e-04\n",
            "Epoch 4/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1590 - accuracy: 0.9568\n",
            "Epoch 4: val_loss improved from 0.17011 to 0.14039, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.1590 - accuracy: 0.9568 - val_loss: 0.1404 - val_accuracy: 0.9596 - lr: 7.0439e-04\n",
            "Epoch 5/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.1406 - accuracy: 0.9606\n",
            "Epoch 5: val_loss improved from 0.14039 to 0.13593, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.1406 - accuracy: 0.9606 - val_loss: 0.1359 - val_accuracy: 0.9618 - lr: 7.0439e-04\n",
            "Epoch 6/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1267 - accuracy: 0.9644\n",
            "Epoch 6: val_loss improved from 0.13593 to 0.10710, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.1267 - accuracy: 0.9644 - val_loss: 0.1071 - val_accuracy: 0.9690 - lr: 7.0439e-04\n",
            "Epoch 7/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1157 - accuracy: 0.9683\n",
            "Epoch 7: val_loss did not improve from 0.10710\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.1157 - accuracy: 0.9683 - val_loss: 0.1072 - val_accuracy: 0.9696 - lr: 7.0439e-04\n",
            "Epoch 8/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1064 - accuracy: 0.9707\n",
            "Epoch 8: val_loss improved from 0.10710 to 0.09313, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.1064 - accuracy: 0.9707 - val_loss: 0.0931 - val_accuracy: 0.9748 - lr: 7.0439e-04\n",
            "Epoch 9/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1052 - accuracy: 0.9709\n",
            "Epoch 9: val_loss improved from 0.09313 to 0.09058, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.1052 - accuracy: 0.9709 - val_loss: 0.0906 - val_accuracy: 0.9742 - lr: 7.0439e-04\n",
            "Epoch 10/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0945 - accuracy: 0.9734\n",
            "Epoch 10: val_loss did not improve from 0.09058\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0945 - accuracy: 0.9734 - val_loss: 0.1074 - val_accuracy: 0.9703 - lr: 7.0439e-04\n",
            "Epoch 11/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.0931 - accuracy: 0.9736\n",
            "Epoch 11: val_loss did not improve from 0.09058\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0931 - accuracy: 0.9736 - val_loss: 0.0916 - val_accuracy: 0.9744 - lr: 7.0439e-04\n",
            "Epoch 12/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.0842 - accuracy: 0.9763\n",
            "Epoch 12: val_loss improved from 0.09058 to 0.08474, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.0843 - accuracy: 0.9763 - val_loss: 0.0847 - val_accuracy: 0.9784 - lr: 7.0439e-04\n",
            "Epoch 13/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.0793 - accuracy: 0.9772\n",
            "Epoch 13: val_loss improved from 0.08474 to 0.08001, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.0794 - accuracy: 0.9772 - val_loss: 0.0800 - val_accuracy: 0.9789 - lr: 7.0439e-04\n",
            "Epoch 14/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0732 - accuracy: 0.9788\n",
            "Epoch 14: val_loss improved from 0.08001 to 0.07890, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0732 - accuracy: 0.9788 - val_loss: 0.0789 - val_accuracy: 0.9781 - lr: 7.0439e-04\n",
            "Epoch 15/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0728 - accuracy: 0.9791\n",
            "Epoch 15: val_loss improved from 0.07890 to 0.06339, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.0728 - accuracy: 0.9791 - val_loss: 0.0634 - val_accuracy: 0.9824 - lr: 7.0439e-04\n",
            "Epoch 16/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0674 - accuracy: 0.9803\n",
            "Epoch 16: val_loss did not improve from 0.06339\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.0674 - accuracy: 0.9803 - val_loss: 0.0752 - val_accuracy: 0.9793 - lr: 7.0439e-04\n",
            "Epoch 17/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0649 - accuracy: 0.9807\n",
            "Epoch 17: val_loss improved from 0.06339 to 0.05783, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0649 - accuracy: 0.9807 - val_loss: 0.0578 - val_accuracy: 0.9848 - lr: 7.0439e-04\n",
            "Epoch 18/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0605 - accuracy: 0.9820\n",
            "Epoch 18: val_loss did not improve from 0.05783\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0605 - accuracy: 0.9820 - val_loss: 0.0674 - val_accuracy: 0.9813 - lr: 7.0439e-04\n",
            "Epoch 19/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.0583 - accuracy: 0.9829\n",
            "Epoch 19: val_loss did not improve from 0.05783\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0583 - accuracy: 0.9829 - val_loss: 0.0641 - val_accuracy: 0.9836 - lr: 7.0439e-04\n",
            "Epoch 20/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0562 - accuracy: 0.9833\n",
            "Epoch 20: val_loss improved from 0.05783 to 0.05312, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.0562 - accuracy: 0.9833 - val_loss: 0.0531 - val_accuracy: 0.9855 - lr: 7.0439e-04\n",
            "Epoch 21/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0543 - accuracy: 0.9837\n",
            "Epoch 21: val_loss did not improve from 0.05312\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0543 - accuracy: 0.9837 - val_loss: 0.0553 - val_accuracy: 0.9852 - lr: 7.0439e-04\n",
            "Epoch 22/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.0513 - accuracy: 0.9844\n",
            "Epoch 22: val_loss did not improve from 0.05312\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.0512 - accuracy: 0.9844 - val_loss: 0.0577 - val_accuracy: 0.9846 - lr: 7.0439e-04\n",
            "Epoch 23/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0501 - accuracy: 0.9850\n",
            "Epoch 23: val_loss did not improve from 0.05312\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0501 - accuracy: 0.9850 - val_loss: 0.0542 - val_accuracy: 0.9858 - lr: 7.0439e-04\n",
            "Epoch 24/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0479 - accuracy: 0.9859\n",
            "Epoch 24: val_loss did not improve from 0.05312\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0479 - accuracy: 0.9859 - val_loss: 0.0650 - val_accuracy: 0.9826 - lr: 7.0439e-04\n",
            "Epoch 25/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0475 - accuracy: 0.9861\n",
            "Epoch 25: val_loss did not improve from 0.05312\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0475 - accuracy: 0.9861 - val_loss: 0.0537 - val_accuracy: 0.9854 - lr: 7.0439e-04\n",
            "Epoch 26/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.0445 - accuracy: 0.9862\n",
            "Epoch 26: val_loss improved from 0.05312 to 0.04948, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0445 - accuracy: 0.9862 - val_loss: 0.0495 - val_accuracy: 0.9868 - lr: 7.0439e-04\n",
            "Epoch 27/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0425 - accuracy: 0.9867\n",
            "Epoch 27: val_loss did not improve from 0.04948\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.0425 - accuracy: 0.9867 - val_loss: 0.0577 - val_accuracy: 0.9854 - lr: 7.0439e-04\n",
            "Epoch 28/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0474 - accuracy: 0.9857\n",
            "Epoch 28: val_loss did not improve from 0.04948\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0474 - accuracy: 0.9857 - val_loss: 0.0528 - val_accuracy: 0.9865 - lr: 7.0439e-04\n",
            "Epoch 29/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.0406 - accuracy: 0.9875\n",
            "Epoch 29: val_loss improved from 0.04948 to 0.04840, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.0407 - accuracy: 0.9875 - val_loss: 0.0484 - val_accuracy: 0.9869 - lr: 7.0439e-04\n",
            "Epoch 30/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9883\n",
            "Epoch 30: val_loss did not improve from 0.04840\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0385 - accuracy: 0.9883 - val_loss: 0.0497 - val_accuracy: 0.9863 - lr: 7.0439e-04\n",
            "Epoch 31/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0383 - accuracy: 0.9882\n",
            "Epoch 31: val_loss did not improve from 0.04840\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.0383 - accuracy: 0.9882 - val_loss: 0.0538 - val_accuracy: 0.9864 - lr: 7.0439e-04\n",
            "Epoch 32/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9886\n",
            "Epoch 32: val_loss did not improve from 0.04840\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0369 - accuracy: 0.9886 - val_loss: 0.0508 - val_accuracy: 0.9872 - lr: 7.0439e-04\n",
            "Epoch 33/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0352 - accuracy: 0.9893\n",
            "Epoch 33: val_loss did not improve from 0.04840\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0352 - accuracy: 0.9893 - val_loss: 0.0498 - val_accuracy: 0.9862 - lr: 7.0439e-04\n",
            "Epoch 34/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0353 - accuracy: 0.9888\n",
            "Epoch 34: val_loss did not improve from 0.04840\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0353 - accuracy: 0.9888 - val_loss: 0.0530 - val_accuracy: 0.9861 - lr: 7.0439e-04\n",
            "Epoch 35/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.0336 - accuracy: 0.9890\n",
            "Epoch 35: val_loss did not improve from 0.04840\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0336 - accuracy: 0.9890 - val_loss: 0.0500 - val_accuracy: 0.9874 - lr: 7.0439e-04\n",
            "Epoch 36/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0337 - accuracy: 0.9895\n",
            "Epoch 36: val_loss did not improve from 0.04840\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.0337 - accuracy: 0.9895 - val_loss: 0.0484 - val_accuracy: 0.9873 - lr: 7.0439e-04\n",
            "Epoch 37/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0318 - accuracy: 0.9899\n",
            "Epoch 37: val_loss improved from 0.04840 to 0.04800, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0318 - accuracy: 0.9899 - val_loss: 0.0480 - val_accuracy: 0.9866 - lr: 7.0439e-04\n",
            "Epoch 38/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9892\n",
            "Epoch 38: val_loss did not improve from 0.04800\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0340 - accuracy: 0.9892 - val_loss: 0.0568 - val_accuracy: 0.9867 - lr: 7.0439e-04\n",
            "Epoch 39/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0306 - accuracy: 0.9902\n",
            "Epoch 39: val_loss did not improve from 0.04800\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0306 - accuracy: 0.9902 - val_loss: 0.0507 - val_accuracy: 0.9869 - lr: 7.0439e-04\n",
            "Epoch 40/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.0301 - accuracy: 0.9904\n",
            "Epoch 40: val_loss did not improve from 0.04800\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.0301 - accuracy: 0.9904 - val_loss: 0.0523 - val_accuracy: 0.9873 - lr: 7.0439e-04\n",
            "Epoch 41/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9908\n",
            "Epoch 41: val_loss did not improve from 0.04800\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0288 - accuracy: 0.9908 - val_loss: 0.0490 - val_accuracy: 0.9885 - lr: 7.0439e-04\n",
            "Epoch 42/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0288 - accuracy: 0.9907\n",
            "Epoch 42: val_loss did not improve from 0.04800\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.0288 - accuracy: 0.9907 - val_loss: 0.0543 - val_accuracy: 0.9870 - lr: 7.0439e-04\n",
            "Epoch 43/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.0275 - accuracy: 0.9912\n",
            "Epoch 43: val_loss improved from 0.04800 to 0.04615, saving model to best_model_LSTM_1layer_with_best_hps.h5\n",
            "2189/2189 [==============================] - 34s 16ms/step - loss: 0.0275 - accuracy: 0.9912 - val_loss: 0.0461 - val_accuracy: 0.9878 - lr: 7.0439e-04\n",
            "Epoch 44/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0281 - accuracy: 0.9908\n",
            "Epoch 44: val_loss did not improve from 0.04615\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0281 - accuracy: 0.9908 - val_loss: 0.0577 - val_accuracy: 0.9853 - lr: 7.0439e-04\n",
            "Epoch 45/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0262 - accuracy: 0.9914\n",
            "Epoch 45: val_loss did not improve from 0.04615\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0262 - accuracy: 0.9914 - val_loss: 0.0503 - val_accuracy: 0.9880 - lr: 7.0439e-04\n",
            "Epoch 46/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0272 - accuracy: 0.9915\n",
            "Epoch 46: val_loss did not improve from 0.04615\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0272 - accuracy: 0.9915 - val_loss: 0.0541 - val_accuracy: 0.9870 - lr: 7.0439e-04\n",
            "Epoch 47/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.0254 - accuracy: 0.9914\n",
            "Epoch 47: val_loss did not improve from 0.04615\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0254 - accuracy: 0.9914 - val_loss: 0.0705 - val_accuracy: 0.9825 - lr: 7.0439e-04\n",
            "Epoch 48/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0266 - accuracy: 0.9913\n",
            "Epoch 48: val_loss did not improve from 0.04615\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0266 - accuracy: 0.9913 - val_loss: 0.0497 - val_accuracy: 0.9884 - lr: 7.0439e-04\n",
            "Epoch 49/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0236 - accuracy: 0.9921\n",
            "Epoch 49: val_loss did not improve from 0.04615\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0236 - accuracy: 0.9921 - val_loss: 0.0597 - val_accuracy: 0.9859 - lr: 7.0439e-04\n",
            "Epoch 50/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0227 - accuracy: 0.9921\n",
            "Epoch 50: val_loss did not improve from 0.04615\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0227 - accuracy: 0.9921 - val_loss: 0.0564 - val_accuracy: 0.9877 - lr: 7.0439e-04\n",
            "Epoch 51/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0242 - accuracy: 0.9922\n",
            "Epoch 51: val_loss did not improve from 0.04615\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0242 - accuracy: 0.9922 - val_loss: 0.0580 - val_accuracy: 0.9870 - lr: 7.0439e-04\n",
            "Epoch 52/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0234 - accuracy: 0.9922\n",
            "Epoch 52: val_loss did not improve from 0.04615\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0234 - accuracy: 0.9922 - val_loss: 0.0526 - val_accuracy: 0.9880 - lr: 7.0439e-04\n",
            "Epoch 53/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9925Restoring model weights from the end of the best epoch: 43.\n",
            "\n",
            "Epoch 53: val_loss did not improve from 0.04615\n",
            "2189/2189 [==============================] - 34s 15ms/step - loss: 0.0214 - accuracy: 0.9925 - val_loss: 0.0565 - val_accuracy: 0.9881 - lr: 7.0439e-04\n",
            "Epoch 53: early stopping\n",
            "548/548 - 3s - loss: 0.0461 - accuracy: 0.9878 - 3s/epoch - 6ms/step\n",
            "Test Loss: 0.046149495989084244\n",
            "Test Accuracy: 0.9878362417221069\n",
            "548/548 [==============================] - 4s 6ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99     14579\n",
            "           1       0.95      0.81      0.87       426\n",
            "           2       0.95      0.97      0.96      1112\n",
            "           3       0.93      0.73      0.82       145\n",
            "           4       0.99      0.99      0.99      1249\n",
            "\n",
            "    accuracy                           0.99     17511\n",
            "   macro avg       0.96      0.90      0.93     17511\n",
            "weighted avg       0.99      0.99      0.99     17511\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# Generating a confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred_classes)\n",
        "\n",
        "# Plotting a confusion matrix\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[0, 1, 2, 3, 4], yticklabels=[0, 1, 2, 3, 4])\n",
        "plt.title(\"Confusion Matrix\")\n",
        "plt.ylabel(\"Actual Label\")\n",
        "plt.xlabel(\"Predicted Label\")\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 681
        },
        "id": "ignBm-cfwz5t",
        "outputId": "a0dcbf1c-5b89-4924-d54a-7a23a65441ef"
      },
      "id": "ignBm-cfwz5t",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x800 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Eg0aF5Z53wEA"
      },
      "id": "Eg0aF5Z53wEA",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tf-gpu] *",
      "language": "python",
      "name": "conda-env-tf-gpu-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}