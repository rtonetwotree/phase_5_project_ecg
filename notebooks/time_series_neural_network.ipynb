{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "8a00172b-9894-4971-a537-441334e1f38d",
      "metadata": {
        "id": "8a00172b-9894-4971-a537-441334e1f38d"
      },
      "source": [
        "## First Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tsfresh\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RWrZla58tcRp",
        "outputId": "58a65e4d-86b8-49ac-afbb-21697636b664"
      },
      "id": "RWrZla58tcRp",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tsfresh\n",
            "  Downloading tsfresh-0.20.2-py2.py3-none-any.whl (95 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/95.8 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.8/95.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.9.1 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (2.31.0)\n",
            "Requirement already satisfied: numpy>=1.15.1 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (1.25.2)\n",
            "Requirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (1.5.3)\n",
            "Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (1.11.4)\n",
            "Requirement already satisfied: statsmodels>=0.13 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (0.14.1)\n",
            "Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (0.5.6)\n",
            "Requirement already satisfied: scikit-learn>=0.22.0 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (1.2.2)\n",
            "Requirement already satisfied: tqdm>=4.10.0 in /usr/local/lib/python3.10/dist-packages (from tsfresh) (4.66.2)\n",
            "Collecting stumpy>=1.7.2 (from tsfresh)\n",
            "  Downloading stumpy-1.12.0-py3-none-any.whl (169 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.1/169.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from tsfresh) (2.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->tsfresh) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.25.0->tsfresh) (2023.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from patsy>=0.4.1->tsfresh) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.1->tsfresh) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.1->tsfresh) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.1->tsfresh) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.9.1->tsfresh) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->tsfresh) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.22.0->tsfresh) (3.3.0)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from statsmodels>=0.13->tsfresh) (23.2)\n",
            "Requirement already satisfied: numba>=0.55.2 in /usr/local/lib/python3.10/dist-packages (from stumpy>=1.7.2->tsfresh) (0.58.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.55.2->stumpy>=1.7.2->tsfresh) (0.41.1)\n",
            "Installing collected packages: stumpy, tsfresh\n",
            "Successfully installed stumpy-1.12.0 tsfresh-0.20.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPQBOk7Rugm3",
        "outputId": "4ed7f244-1387-488a-ae96-9d1c361ae075"
      },
      "id": "BPQBOk7Rugm3",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "96435299-050b-4010-b57c-cc490b83b705",
      "metadata": {
        "id": "96435299-050b-4010-b57c-cc490b83b705"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tsfresh import extract_features\n",
        "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
        "\n",
        "# If you need to plot or visualize data later on\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# For any data preprocessing or manipulation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Depending on the models you plan to use\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "38da3325-d76d-421e-94d0-0596c6b95d3b",
      "metadata": {
        "id": "38da3325-d76d-421e-94d0-0596c6b95d3b"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "37dbff3e-7b6b-4798-9190-3d0180925068",
      "metadata": {
        "id": "37dbff3e-7b6b-4798-9190-3d0180925068"
      },
      "outputs": [],
      "source": [
        "fazeli_mitbih_train_df = pd.read_csv('/content/drive/MyDrive/mitbih_train.csv', header=None)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fazeli_mitbih_test_df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/mitbih_test.csv', header=None)"
      ],
      "metadata": {
        "id": "KwjAVYgmE55a"
      },
      "id": "KwjAVYgmE55a",
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "74aed28a-031c-4298-a7f8-3d01d46e93be",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74aed28a-031c-4298-a7f8-3d01d46e93be",
        "outputId": "ef63667f-278f-4e77-d4b8-11f23349010d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.0    72471\n",
              "4.0     6431\n",
              "2.0     5788\n",
              "1.0     2223\n",
              "3.0      641\n",
              "Name: 187, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "column_187 = fazeli_mitbih_train_df.iloc[:, 187]\n",
        "column_187.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dee19804-7f3c-4139-8068-df2c0700db04",
      "metadata": {
        "id": "dee19804-7f3c-4139-8068-df2c0700db04"
      },
      "source": [
        "## Comprehensive Feature Extraction\n",
        "\n",
        "using tsfresh time series comprehensive feature extraction package"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e950b2da-a4ef-4a60-b0bf-c3be621ba4da",
      "metadata": {
        "id": "e950b2da-a4ef-4a60-b0bf-c3be621ba4da"
      },
      "source": [
        "### Next cell takes 15-30 min to run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eb38587e-4ec4-449d-80dd-366aa28a7e83",
      "metadata": {
        "id": "eb38587e-4ec4-449d-80dd-366aa28a7e83",
        "outputId": "b7e2185c-252b-40cc-ad06-23f54b84b468"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Feature Extraction:   0%|                                | 0/35 [00:00<?, ?it/s]/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "Feature Extraction: 100%|███████████████████████| 35/35 [01:07<00:00,  1.92s/it]\n",
            "Feature Extraction:   0%|                                | 0/35 [00:00<?, ?it/s]/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "Feature Extraction: 100%|███████████████████████| 35/35 [01:09<00:00,  1.98s/it]\n",
            "Feature Extraction:   0%|                                | 0/35 [00:00<?, ?it/s]/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "Feature Extraction: 100%|███████████████████████| 35/35 [01:11<00:00,  2.05s/it]\n",
            "Feature Extraction:   0%|                                | 0/35 [00:00<?, ?it/s]/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "Feature Extraction: 100%|███████████████████████| 35/35 [01:12<00:00,  2.07s/it]\n",
            "Feature Extraction:   0%|                                | 0/35 [00:00<?, ?it/s]/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Feature Extraction: 100%|███████████████████████| 35/35 [01:13<00:00,  2.10s/it]\n",
            "Feature Extraction:   0%|                                | 0/35 [00:00<?, ?it/s]/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "Feature Extraction: 100%|███████████████████████| 35/35 [01:12<00:00,  2.07s/it]\n",
            "Feature Extraction:   0%|                                | 0/35 [00:00<?, ?it/s]/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "Feature Extraction: 100%|███████████████████████| 35/35 [01:14<00:00,  2.14s/it]\n",
            "Feature Extraction:   0%|                                | 0/35 [00:00<?, ?it/s]/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "Feature Extraction: 100%|███████████████████████| 35/35 [01:16<00:00,  2.18s/it]\n",
            "Feature Extraction:   0%|                                | 0/35 [00:00<?, ?it/s]/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "/Users/ry/anaconda3/envs/tf-gpu/lib/python3.9/site-packages/dask/dataframe/_pyarrow_compat.py:17: FutureWarning: Minimal version of pyarrow will soon be increased to 14.0.1. You are using 12.0.1. Please consider upgrading.\n",
            "  warnings.warn(\n",
            "Feature Extraction: 100%|███████████████████████| 35/35 [00:58<00:00,  1.68s/it]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from tsfresh import extract_features\n",
        "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
        "\n",
        "# Load your dataset\n",
        "fazeli_mitbih_train_df = pd.read_csv('../data/mitbih_train.csv', header=None)\n",
        "\n",
        "# Assign a unique ID to each row and separate the target variable\n",
        "fazeli_mitbih_train_df['id'] = range(len(fazeli_mitbih_train_df))\n",
        "target_series = fazeli_mitbih_train_df[187]\n",
        "\n",
        "# Keep only features and the unique ID for feature extraction\n",
        "fazeli_mitbih_train_df_features_only = fazeli_mitbih_train_df.drop(columns=[187])\n",
        "\n",
        "# Convert to long format, preserving the 'id' for direct mapping\n",
        "long_df = fazeli_mitbih_train_df_features_only.melt(id_vars='id', var_name='time', value_name='amplitude')\n",
        "\n",
        "# Define feature extraction settings\n",
        "extraction_settings = ComprehensiveFCParameters()\n",
        "\n",
        "# Incremental extraction setup\n",
        "unique_ids = long_df['id'].unique()\n",
        "subset_size = 10000  # Adjust based on your dataset size and memory constraints\n",
        "extracted_features_list = []\n",
        "\n",
        "for i in range(0, len(unique_ids), subset_size):\n",
        "    subset_ids = unique_ids[i:i+subset_size]\n",
        "    subset_df = long_df[long_df['id'].isin(subset_ids)]\n",
        "\n",
        "    # Extract features for this subset\n",
        "    subset_features = extract_features(subset_df, column_id='id', column_sort='time',\n",
        "                                       default_fc_parameters=extraction_settings, n_jobs=7)\n",
        "    extracted_features_list.append(subset_features)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ceb8dc3-bb1a-4fc1-8789-1b8cc965c9b9",
      "metadata": {
        "id": "5ceb8dc3-bb1a-4fc1-8789-1b8cc965c9b9",
        "outputId": "c94316b1-ca30-4c71-931c-0d8ac4f1695a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   label\n",
            "0    0.0\n",
            "1    0.0\n",
            "2    0.0\n",
            "3    0.0\n",
            "4    0.0\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Combine extracted features from all subsets\n",
        "extracted_features = pd.concat(extracted_features_list)\n",
        "\n",
        "# Re-associate the target labels using the 'id' column\n",
        "# This step correctly maps the original labels to the extracted features based on 'id'\n",
        "extracted_features['label'] = extracted_features.index.map(lambda idx: target_series.loc[idx])\n",
        "\n",
        "# Verify the re-association of labels\n",
        "print(extracted_features[['label']].head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58082168-ea63-41ed-92ca-4a2a80362104",
      "metadata": {
        "id": "58082168-ea63-41ed-92ca-4a2a80362104",
        "outputId": "4b66595d-401d-44a3-a6aa-a1b39da60007"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "label\n",
              "0.0    72471\n",
              "4.0     6431\n",
              "2.0     5788\n",
              "1.0     2223\n",
              "3.0      641\n",
              "Name: count, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "column_187_extracted = extracted_features['label']\n",
        "column_187_extracted.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b7c62a9e-4a10-42fe-ab0e-f70e12238336",
      "metadata": {
        "id": "b7c62a9e-4a10-42fe-ab0e-f70e12238336"
      },
      "source": [
        "## Set X and y from extracted features, Perform train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "08955da9-01b4-4570-98af-fd2227d80f70",
      "metadata": {
        "id": "08955da9-01b4-4570-98af-fd2227d80f70"
      },
      "outputs": [],
      "source": [
        "# Setting X and y from my extracted features\n",
        "X = extracted_features.drop('label', axis=1)\n",
        "y = extracted_features['label']\n",
        "\n",
        "# Split data into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3376e4c2-e6a3-41fc-8edd-3580bf98081c",
      "metadata": {
        "id": "3376e4c2-e6a3-41fc-8edd-3580bf98081c"
      },
      "source": [
        "# WIP Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the model on the test data\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=2)\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYtB2Z0lyVMs",
        "outputId": "ac16978f-8ace-4823-a2e7-c1960fde5a0e"
      },
      "id": "nYtB2Z0lyVMs",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "548/548 - 1s - loss: 0.0623 - accuracy: 0.9837 - 1s/epoch - 2ms/step\n",
            "Test Accuracy: 0.9837245345115662\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Predict the classes with the model\n",
        "predictions = model.predict(X_test)\n",
        "\n",
        "# Convert predictions from one-hot encoded vectors to class labels\n",
        "predicted_labels = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Convert true labels from one-hot encoded vectors to class labels\n",
        "true_labels = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Now you can compute the confusion matrix and plot it as previously described\n",
        "cm = confusion_matrix(true_labels, predicted_labels)\n",
        "\n",
        "# Plot the confusion matrix\n",
        "plt.figure(figsize=(10, 7))\n",
        "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\", \"Class 4\"], yticklabels=[\"Class 0\", \"Class 1\", \"Class 2\", \"Class 3\", \"Class 4\"])\n",
        "plt.title('Confusion Matrix')\n",
        "plt.xlabel('Predicted Labels')\n",
        "plt.ylabel('True Labels')\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "RcxsydaayaCu",
        "outputId": "20b8a8d7-9ef8-44c4-857b-021f472f00c4"
      },
      "id": "RcxsydaayaCu",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "548/548 [==============================] - 1s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x700 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, Dense, Dropout\n",
        "\n",
        "# Assuming your input shape is (timesteps, features)\n",
        "input_shape = (187, 1)  # Adjusted input shape to match your dataset\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=input_shape),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv1D(filters=256, kernel_size=3, activation='relu'),\n",
        "    GlobalAveragePooling1D(),\n",
        "\n",
        "    Dense(100, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation='softmax')  # Adjusted for 5 classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "11PLqEnMyWwo",
        "outputId": "c1abad8c-e65c-450a-eb70-db389ffc54b9"
      },
      "id": "11PLqEnMyWwo",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 183, 64)           384       \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1  (None, 91, 64)            0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 91, 64)            0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 89, 128)           24704     \n",
            "                                                                 \n",
            " max_pooling1d_1 (MaxPoolin  (None, 44, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 44, 128)           0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 42, 256)           98560     \n",
            "                                                                 \n",
            " global_average_pooling1d (  (None, 256)               0         \n",
            " GlobalAveragePooling1D)                                         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 100)               25700     \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 5)                 505       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 149853 (585.36 KB)\n",
            "Trainable params: 149853 (585.36 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "a8249bc9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8249bc9",
        "outputId": "85d6ff71-ab0c-45be-f54f-8082bb90fd55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "2189/2189 [==============================] - 16s 5ms/step - loss: 0.4301 - accuracy: 0.8802 - val_loss: 0.2590 - val_accuracy: 0.9272\n",
            "Epoch 2/10\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.2541 - accuracy: 0.9300 - val_loss: 0.2095 - val_accuracy: 0.9407\n",
            "Epoch 3/10\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.2117 - accuracy: 0.9406 - val_loss: 0.1713 - val_accuracy: 0.9485\n",
            "Epoch 4/10\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.1876 - accuracy: 0.9476 - val_loss: 0.1489 - val_accuracy: 0.9556\n",
            "Epoch 5/10\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.1692 - accuracy: 0.9517 - val_loss: 0.1395 - val_accuracy: 0.9603\n",
            "Epoch 6/10\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.1561 - accuracy: 0.9564 - val_loss: 0.1250 - val_accuracy: 0.9633\n",
            "Epoch 7/10\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.1436 - accuracy: 0.9600 - val_loss: 0.1104 - val_accuracy: 0.9689\n",
            "Epoch 8/10\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.1336 - accuracy: 0.9631 - val_loss: 0.1069 - val_accuracy: 0.9691\n",
            "Epoch 9/10\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.1294 - accuracy: 0.9652 - val_loss: 0.1021 - val_accuracy: 0.9702\n",
            "Epoch 10/10\n",
            "2189/2189 [==============================] - 10s 4ms/step - loss: 0.1232 - accuracy: 0.9660 - val_loss: 0.1192 - val_accuracy: 0.9651\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x790a5f51b280>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Assuming fazeli_mitbih_train_df is your DataFrame and the last column is the label\n",
        "X = fazeli_mitbih_train_df.iloc[:, :-1].values\n",
        "y = fazeli_mitbih_train_df.iloc[:, -1].values\n",
        "\n",
        "# Reshape X to fit the Conv1D input requirements and convert y to categorical\n",
        "X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "y_categorical = to_categorical(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=10, validation_data=(X_test, y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# Assuming fazeli_mitbih_train_df is your DataFrame and the last column is the label\n",
        "X = fazeli_mitbih_train_df.iloc[:, :-1].values\n",
        "y = fazeli_mitbih_train_df.iloc[:, -1].values\n",
        "\n",
        "# Reshape X to fit the Conv1D input requirements and convert y to categorical\n",
        "X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "y_categorical = to_categorical(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_model.h5',  # Path where to save the model\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,  # Only save the best model\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Define the ReduceLROnPlateau callback\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=0.001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model with the callbacks\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=100,  # Adjust the number of epochs if necessary\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping, reduce_lr, model_checkpoint]  # Add ModelCheckpoint to the callbacks list\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRK7-VA-9SNz",
        "outputId": "3dfa4832-f99d-4295-9799-2c5a54ede835"
      },
      "id": "sRK7-VA-9SNz",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2180/2189 [============================>.] - ETA: 0s - loss: 0.1183 - accuracy: 0.9681\n",
            "Epoch 1: val_loss improved from inf to 0.09765, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.1184 - accuracy: 0.9681 - val_loss: 0.0976 - val_accuracy: 0.9736 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "  39/2189 [..............................] - ETA: 8s - loss: 0.1191 - accuracy: 0.9696"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2181/2189 [============================>.] - ETA: 0s - loss: 0.1127 - accuracy: 0.9690\n",
            "Epoch 2: val_loss improved from 0.09765 to 0.09134, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.1125 - accuracy: 0.9690 - val_loss: 0.0913 - val_accuracy: 0.9742 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "2181/2189 [============================>.] - ETA: 0s - loss: 0.1088 - accuracy: 0.9703\n",
            "Epoch 3: val_loss did not improve from 0.09134\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.1087 - accuracy: 0.9704 - val_loss: 0.0951 - val_accuracy: 0.9745 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.1039 - accuracy: 0.9714\n",
            "Epoch 4: val_loss improved from 0.09134 to 0.08341, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.1039 - accuracy: 0.9714 - val_loss: 0.0834 - val_accuracy: 0.9760 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "2186/2189 [============================>.] - ETA: 0s - loss: 0.1013 - accuracy: 0.9719\n",
            "Epoch 5: val_loss improved from 0.08341 to 0.08326, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.1013 - accuracy: 0.9719 - val_loss: 0.0833 - val_accuracy: 0.9767 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "2184/2189 [============================>.] - ETA: 0s - loss: 0.1007 - accuracy: 0.9725\n",
            "Epoch 6: val_loss did not improve from 0.08326\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.1007 - accuracy: 0.9725 - val_loss: 0.0953 - val_accuracy: 0.9744 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "2184/2189 [============================>.] - ETA: 0s - loss: 0.0963 - accuracy: 0.9738\n",
            "Epoch 7: val_loss improved from 0.08326 to 0.08261, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0965 - accuracy: 0.9738 - val_loss: 0.0826 - val_accuracy: 0.9788 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "2181/2189 [============================>.] - ETA: 0s - loss: 0.0938 - accuracy: 0.9745\n",
            "Epoch 8: val_loss improved from 0.08261 to 0.08088, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0936 - accuracy: 0.9746 - val_loss: 0.0809 - val_accuracy: 0.9772 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "2182/2189 [============================>.] - ETA: 0s - loss: 0.0895 - accuracy: 0.9755\n",
            "Epoch 9: val_loss improved from 0.08088 to 0.07768, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0894 - accuracy: 0.9756 - val_loss: 0.0777 - val_accuracy: 0.9788 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "2182/2189 [============================>.] - ETA: 0s - loss: 0.0897 - accuracy: 0.9745\n",
            "Epoch 10: val_loss improved from 0.07768 to 0.07697, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0896 - accuracy: 0.9745 - val_loss: 0.0770 - val_accuracy: 0.9788 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "2186/2189 [============================>.] - ETA: 0s - loss: 0.0873 - accuracy: 0.9765\n",
            "Epoch 11: val_loss improved from 0.07697 to 0.06820, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0872 - accuracy: 0.9765 - val_loss: 0.0682 - val_accuracy: 0.9804 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "2186/2189 [============================>.] - ETA: 0s - loss: 0.0850 - accuracy: 0.9765\n",
            "Epoch 12: val_loss did not improve from 0.06820\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0852 - accuracy: 0.9765 - val_loss: 0.0767 - val_accuracy: 0.9782 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "2183/2189 [============================>.] - ETA: 0s - loss: 0.0824 - accuracy: 0.9771\n",
            "Epoch 13: val_loss did not improve from 0.06820\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0825 - accuracy: 0.9771 - val_loss: 0.0728 - val_accuracy: 0.9804 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "2185/2189 [============================>.] - ETA: 0s - loss: 0.0820 - accuracy: 0.9776\n",
            "Epoch 14: val_loss did not improve from 0.06820\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0820 - accuracy: 0.9776 - val_loss: 0.0709 - val_accuracy: 0.9806 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "2180/2189 [============================>.] - ETA: 0s - loss: 0.0792 - accuracy: 0.9780\n",
            "Epoch 15: val_loss did not improve from 0.06820\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0791 - accuracy: 0.9781 - val_loss: 0.0720 - val_accuracy: 0.9809 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "2177/2189 [============================>.] - ETA: 0s - loss: 0.0789 - accuracy: 0.9781\n",
            "Epoch 16: val_loss improved from 0.06820 to 0.06663, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0790 - accuracy: 0.9780 - val_loss: 0.0666 - val_accuracy: 0.9814 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "2177/2189 [============================>.] - ETA: 0s - loss: 0.0751 - accuracy: 0.9790\n",
            "Epoch 17: val_loss did not improve from 0.06663\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0753 - accuracy: 0.9790 - val_loss: 0.0670 - val_accuracy: 0.9825 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "2182/2189 [============================>.] - ETA: 0s - loss: 0.0757 - accuracy: 0.9790\n",
            "Epoch 18: val_loss did not improve from 0.06663\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0757 - accuracy: 0.9790 - val_loss: 0.0690 - val_accuracy: 0.9798 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "2177/2189 [============================>.] - ETA: 0s - loss: 0.0734 - accuracy: 0.9794\n",
            "Epoch 19: val_loss did not improve from 0.06663\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0733 - accuracy: 0.9794 - val_loss: 0.0702 - val_accuracy: 0.9804 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "2180/2189 [============================>.] - ETA: 0s - loss: 0.0714 - accuracy: 0.9801\n",
            "Epoch 20: val_loss improved from 0.06663 to 0.06609, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0714 - accuracy: 0.9800 - val_loss: 0.0661 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "2182/2189 [============================>.] - ETA: 0s - loss: 0.0713 - accuracy: 0.9803\n",
            "Epoch 21: val_loss did not improve from 0.06609\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0713 - accuracy: 0.9803 - val_loss: 0.0708 - val_accuracy: 0.9825 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "2180/2189 [============================>.] - ETA: 0s - loss: 0.0703 - accuracy: 0.9802\n",
            "Epoch 22: val_loss did not improve from 0.06609\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0702 - accuracy: 0.9803 - val_loss: 0.0671 - val_accuracy: 0.9817 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.0685 - accuracy: 0.9810\n",
            "Epoch 23: val_loss did not improve from 0.06609\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0685 - accuracy: 0.9810 - val_loss: 0.0679 - val_accuracy: 0.9821 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.0682 - accuracy: 0.9803\n",
            "Epoch 24: val_loss did not improve from 0.06609\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0681 - accuracy: 0.9803 - val_loss: 0.0683 - val_accuracy: 0.9817 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "2185/2189 [============================>.] - ETA: 0s - loss: 0.0672 - accuracy: 0.9809\n",
            "Epoch 25: val_loss did not improve from 0.06609\n",
            "2189/2189 [==============================] - 10s 4ms/step - loss: 0.0671 - accuracy: 0.9809 - val_loss: 0.0668 - val_accuracy: 0.9825 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "2180/2189 [============================>.] - ETA: 0s - loss: 0.0662 - accuracy: 0.9812\n",
            "Epoch 26: val_loss did not improve from 0.06609\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0662 - accuracy: 0.9812 - val_loss: 0.0701 - val_accuracy: 0.9823 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.0644 - accuracy: 0.9813\n",
            "Epoch 27: val_loss did not improve from 0.06609\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0643 - accuracy: 0.9814 - val_loss: 0.0724 - val_accuracy: 0.9817 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "2182/2189 [============================>.] - ETA: 0s - loss: 0.0637 - accuracy: 0.9818\n",
            "Epoch 28: val_loss improved from 0.06609 to 0.06451, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0637 - accuracy: 0.9818 - val_loss: 0.0645 - val_accuracy: 0.9824 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "2185/2189 [============================>.] - ETA: 0s - loss: 0.0637 - accuracy: 0.9819\n",
            "Epoch 29: val_loss improved from 0.06451 to 0.06232, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0636 - accuracy: 0.9819 - val_loss: 0.0623 - val_accuracy: 0.9837 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "2180/2189 [============================>.] - ETA: 0s - loss: 0.0628 - accuracy: 0.9820\n",
            "Epoch 30: val_loss did not improve from 0.06232\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0627 - accuracy: 0.9820 - val_loss: 0.0671 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "2180/2189 [============================>.] - ETA: 0s - loss: 0.0620 - accuracy: 0.9824\n",
            "Epoch 31: val_loss did not improve from 0.06232\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0619 - accuracy: 0.9824 - val_loss: 0.0670 - val_accuracy: 0.9826 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0601 - accuracy: 0.9825\n",
            "Epoch 32: val_loss did not improve from 0.06232\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0601 - accuracy: 0.9825 - val_loss: 0.0663 - val_accuracy: 0.9826 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "2181/2189 [============================>.] - ETA: 0s - loss: 0.0608 - accuracy: 0.9822\n",
            "Epoch 33: val_loss did not improve from 0.06232\n",
            "2189/2189 [==============================] - 10s 4ms/step - loss: 0.0608 - accuracy: 0.9822 - val_loss: 0.0634 - val_accuracy: 0.9840 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "2178/2189 [============================>.] - ETA: 0s - loss: 0.0585 - accuracy: 0.9835\n",
            "Epoch 34: val_loss did not improve from 0.06232\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0585 - accuracy: 0.9834 - val_loss: 0.0654 - val_accuracy: 0.9821 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "2181/2189 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9831\n",
            "Epoch 35: val_loss did not improve from 0.06232\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0589 - accuracy: 0.9831 - val_loss: 0.0627 - val_accuracy: 0.9830 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "2181/2189 [============================>.] - ETA: 0s - loss: 0.0589 - accuracy: 0.9830\n",
            "Epoch 36: val_loss did not improve from 0.06232\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0590 - accuracy: 0.9830 - val_loss: 0.0635 - val_accuracy: 0.9832 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "2186/2189 [============================>.] - ETA: 0s - loss: 0.0562 - accuracy: 0.9832\n",
            "Epoch 37: val_loss did not improve from 0.06232\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0562 - accuracy: 0.9832 - val_loss: 0.0647 - val_accuracy: 0.9832 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "2186/2189 [============================>.] - ETA: 0s - loss: 0.0570 - accuracy: 0.9832\n",
            "Epoch 38: val_loss did not improve from 0.06232\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0569 - accuracy: 0.9832 - val_loss: 0.0667 - val_accuracy: 0.9835 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "2185/2189 [============================>.] - ETA: 0s - loss: 0.0571 - accuracy: 0.9829Restoring model weights from the end of the best epoch: 29.\n",
            "\n",
            "Epoch 39: val_loss did not improve from 0.06232\n",
            "2189/2189 [==============================] - 10s 5ms/step - loss: 0.0571 - accuracy: 0.9829 - val_loss: 0.0666 - val_accuracy: 0.9824 - lr: 0.0010\n",
            "Epoch 39: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, GlobalAveragePooling1D, Dense, Dropout, BatchNormalization\n",
        "\n",
        "# Assuming your input shape is (timesteps, features)\n",
        "input_shape = (187, 1)  # Adjusted input shape to match your dataset\n",
        "\n",
        "model = Sequential([\n",
        "    Conv1D(filters=64, kernel_size=5, activation='relu', input_shape=input_shape),\n",
        "    BatchNormalization(),  # Batch Normalization layer after Convolution\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
        "    BatchNormalization(),  # Another Batch Normalization layer\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Dropout(0.1),\n",
        "\n",
        "    Conv1D(filters=256, kernel_size=3, activation='relu'),\n",
        "    BatchNormalization(),  # And another one\n",
        "    GlobalAveragePooling1D(),\n",
        "\n",
        "    Dense(100, activation='relu'),\n",
        "    Dropout(0.5),\n",
        "    Dense(5, activation='softmax')  # Adjusted for 5 classes\n",
        "])\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJcPnKch3GC9",
        "outputId": "42ab9379-57ca-4920-f09a-b759f3ceadca"
      },
      "id": "ZJcPnKch3GC9",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d_3 (Conv1D)           (None, 183, 64)           384       \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 183, 64)           256       \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " max_pooling1d_2 (MaxPoolin  (None, 91, 64)            0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 91, 64)            0         \n",
            "                                                                 \n",
            " conv1d_4 (Conv1D)           (None, 89, 128)           24704     \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 89, 128)           512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling1d_3 (MaxPoolin  (None, 44, 128)           0         \n",
            " g1D)                                                            \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 44, 128)           0         \n",
            "                                                                 \n",
            " conv1d_5 (Conv1D)           (None, 42, 256)           98560     \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 42, 256)           1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " global_average_pooling1d_1  (None, 256)               0         \n",
            "  (GlobalAveragePooling1D)                                       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 100)               25700     \n",
            "                                                                 \n",
            " dropout_5 (Dropout)         (None, 100)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 5)                 505       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 151645 (592.36 KB)\n",
            "Trainable params: 150749 (588.86 KB)\n",
            "Non-trainable params: 896 (3.50 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
        "\n",
        "# Assuming fazeli_mitbih_train_df is your DataFrame and the last column is the label\n",
        "X = fazeli_mitbih_train_df.iloc[:, :-1].values\n",
        "y = fazeli_mitbih_train_df.iloc[:, -1].values\n",
        "\n",
        "# Reshape X to fit the Conv1D input requirements and convert y to categorical\n",
        "X_reshaped = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "y_categorical = to_categorical(y)\n",
        "\n",
        "# Split the data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_reshaped, y_categorical, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the ModelCheckpoint callback\n",
        "model_checkpoint = ModelCheckpoint(\n",
        "    'best_model.h5',  # Path where to save the model\n",
        "    monitor='val_loss',\n",
        "    save_best_only=True,  # Only save the best model\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Define the early stopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=10,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "# Define the ReduceLROnPlateau callback\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=5,\n",
        "    min_lr=0.001,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# Train the model with the callbacks\n",
        "history = model.fit(\n",
        "    X_train,\n",
        "    y_train,\n",
        "    epochs=100,  # Adjust the number of epochs if necessary\n",
        "    validation_data=(X_test, y_test),\n",
        "    callbacks=[early_stopping, reduce_lr, model_checkpoint]  # Add ModelCheckpoint to the callbacks list\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uXN32U4WAonf",
        "outputId": "95147839-c363-4236-f205-259c99fa8cf1"
      },
      "id": "uXN32U4WAonf",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "2183/2189 [============================>.] - ETA: 0s - loss: 0.2579 - accuracy: 0.9287\n",
            "Epoch 1: val_loss improved from inf to 0.15190, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 18s 7ms/step - loss: 0.2580 - accuracy: 0.9287 - val_loss: 0.1519 - val_accuracy: 0.9611 - lr: 0.0010\n",
            "Epoch 2/100\n",
            "  19/2189 [..............................] - ETA: 13s - loss: 0.1197 - accuracy: 0.9655"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2185/2189 [============================>.] - ETA: 0s - loss: 0.1517 - accuracy: 0.9583\n",
            "Epoch 2: val_loss did not improve from 0.15190\n",
            "2189/2189 [==============================] - 14s 6ms/step - loss: 0.1516 - accuracy: 0.9584 - val_loss: 0.1894 - val_accuracy: 0.9445 - lr: 0.0010\n",
            "Epoch 3/100\n",
            "2186/2189 [============================>.] - ETA: 0s - loss: 0.1279 - accuracy: 0.9650\n",
            "Epoch 3: val_loss improved from 0.15190 to 0.10350, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.1280 - accuracy: 0.9650 - val_loss: 0.1035 - val_accuracy: 0.9707 - lr: 0.0010\n",
            "Epoch 4/100\n",
            "2182/2189 [============================>.] - ETA: 0s - loss: 0.1175 - accuracy: 0.9677\n",
            "Epoch 4: val_loss improved from 0.10350 to 0.09959, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.1175 - accuracy: 0.9677 - val_loss: 0.0996 - val_accuracy: 0.9750 - lr: 0.0010\n",
            "Epoch 5/100\n",
            "2186/2189 [============================>.] - ETA: 0s - loss: 0.1080 - accuracy: 0.9701\n",
            "Epoch 5: val_loss improved from 0.09959 to 0.08106, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.1080 - accuracy: 0.9701 - val_loss: 0.0811 - val_accuracy: 0.9772 - lr: 0.0010\n",
            "Epoch 6/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 0.9725\n",
            "Epoch 6: val_loss did not improve from 0.08106\n",
            "2189/2189 [==============================] - 14s 7ms/step - loss: 0.0985 - accuracy: 0.9725 - val_loss: 0.1212 - val_accuracy: 0.9621 - lr: 0.0010\n",
            "Epoch 7/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.0946 - accuracy: 0.9743\n",
            "Epoch 7: val_loss did not improve from 0.08106\n",
            "2189/2189 [==============================] - 14s 7ms/step - loss: 0.0945 - accuracy: 0.9743 - val_loss: 0.1010 - val_accuracy: 0.9721 - lr: 0.0010\n",
            "Epoch 8/100\n",
            "2182/2189 [============================>.] - ETA: 0s - loss: 0.0909 - accuracy: 0.9748\n",
            "Epoch 8: val_loss improved from 0.08106 to 0.07551, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0909 - accuracy: 0.9748 - val_loss: 0.0755 - val_accuracy: 0.9770 - lr: 0.0010\n",
            "Epoch 9/100\n",
            "2186/2189 [============================>.] - ETA: 0s - loss: 0.0871 - accuracy: 0.9762\n",
            "Epoch 9: val_loss improved from 0.07551 to 0.06947, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0871 - accuracy: 0.9763 - val_loss: 0.0695 - val_accuracy: 0.9822 - lr: 0.0010\n",
            "Epoch 10/100\n",
            "2181/2189 [============================>.] - ETA: 0s - loss: 0.0833 - accuracy: 0.9773\n",
            "Epoch 10: val_loss improved from 0.06947 to 0.06794, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0832 - accuracy: 0.9773 - val_loss: 0.0679 - val_accuracy: 0.9814 - lr: 0.0010\n",
            "Epoch 11/100\n",
            "2182/2189 [============================>.] - ETA: 0s - loss: 0.0822 - accuracy: 0.9770\n",
            "Epoch 11: val_loss did not improve from 0.06794\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0821 - accuracy: 0.9770 - val_loss: 0.0767 - val_accuracy: 0.9786 - lr: 0.0010\n",
            "Epoch 12/100\n",
            "2182/2189 [============================>.] - ETA: 0s - loss: 0.0779 - accuracy: 0.9783\n",
            "Epoch 12: val_loss improved from 0.06794 to 0.06559, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0780 - accuracy: 0.9783 - val_loss: 0.0656 - val_accuracy: 0.9819 - lr: 0.0010\n",
            "Epoch 13/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0767 - accuracy: 0.9788\n",
            "Epoch 13: val_loss did not improve from 0.06559\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0767 - accuracy: 0.9788 - val_loss: 0.0749 - val_accuracy: 0.9791 - lr: 0.0010\n",
            "Epoch 14/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.0752 - accuracy: 0.9794\n",
            "Epoch 14: val_loss did not improve from 0.06559\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0753 - accuracy: 0.9794 - val_loss: 0.2018 - val_accuracy: 0.9464 - lr: 0.0010\n",
            "Epoch 15/100\n",
            "2184/2189 [============================>.] - ETA: 0s - loss: 0.0717 - accuracy: 0.9802\n",
            "Epoch 15: val_loss improved from 0.06559 to 0.06092, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0716 - accuracy: 0.9803 - val_loss: 0.0609 - val_accuracy: 0.9826 - lr: 0.0010\n",
            "Epoch 16/100\n",
            "2184/2189 [============================>.] - ETA: 0s - loss: 0.0721 - accuracy: 0.9798\n",
            "Epoch 16: val_loss did not improve from 0.06092\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0720 - accuracy: 0.9799 - val_loss: 0.0658 - val_accuracy: 0.9818 - lr: 0.0010\n",
            "Epoch 17/100\n",
            "2186/2189 [============================>.] - ETA: 0s - loss: 0.0693 - accuracy: 0.9803\n",
            "Epoch 17: val_loss did not improve from 0.06092\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0693 - accuracy: 0.9803 - val_loss: 0.0694 - val_accuracy: 0.9809 - lr: 0.0010\n",
            "Epoch 18/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.0665 - accuracy: 0.9810\n",
            "Epoch 18: val_loss did not improve from 0.06092\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0664 - accuracy: 0.9811 - val_loss: 0.0786 - val_accuracy: 0.9805 - lr: 0.0010\n",
            "Epoch 19/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0658 - accuracy: 0.9811\n",
            "Epoch 19: val_loss did not improve from 0.06092\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0658 - accuracy: 0.9811 - val_loss: 0.0740 - val_accuracy: 0.9805 - lr: 0.0010\n",
            "Epoch 20/100\n",
            "2182/2189 [============================>.] - ETA: 0s - loss: 0.0650 - accuracy: 0.9810\n",
            "Epoch 20: val_loss did not improve from 0.06092\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0650 - accuracy: 0.9810 - val_loss: 0.0670 - val_accuracy: 0.9824 - lr: 0.0010\n",
            "Epoch 21/100\n",
            "2185/2189 [============================>.] - ETA: 0s - loss: 0.0641 - accuracy: 0.9816\n",
            "Epoch 21: val_loss did not improve from 0.06092\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0641 - accuracy: 0.9816 - val_loss: 0.0702 - val_accuracy: 0.9816 - lr: 0.0010\n",
            "Epoch 22/100\n",
            "2181/2189 [============================>.] - ETA: 0s - loss: 0.0621 - accuracy: 0.9820\n",
            "Epoch 22: val_loss did not improve from 0.06092\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0621 - accuracy: 0.9820 - val_loss: 0.1484 - val_accuracy: 0.9689 - lr: 0.0010\n",
            "Epoch 23/100\n",
            "2183/2189 [============================>.] - ETA: 0s - loss: 0.0615 - accuracy: 0.9823\n",
            "Epoch 23: val_loss did not improve from 0.06092\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0616 - accuracy: 0.9823 - val_loss: 0.0732 - val_accuracy: 0.9812 - lr: 0.0010\n",
            "Epoch 24/100\n",
            "2182/2189 [============================>.] - ETA: 0s - loss: 0.0609 - accuracy: 0.9819\n",
            "Epoch 24: val_loss improved from 0.06092 to 0.05970, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 14s 7ms/step - loss: 0.0608 - accuracy: 0.9820 - val_loss: 0.0597 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 25/100\n",
            "2183/2189 [============================>.] - ETA: 0s - loss: 0.0595 - accuracy: 0.9830\n",
            "Epoch 25: val_loss did not improve from 0.05970\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0595 - accuracy: 0.9830 - val_loss: 0.1028 - val_accuracy: 0.9702 - lr: 0.0010\n",
            "Epoch 26/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0595 - accuracy: 0.9827\n",
            "Epoch 26: val_loss did not improve from 0.05970\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0595 - accuracy: 0.9827 - val_loss: 0.0667 - val_accuracy: 0.9841 - lr: 0.0010\n",
            "Epoch 27/100\n",
            "2184/2189 [============================>.] - ETA: 0s - loss: 0.0572 - accuracy: 0.9839\n",
            "Epoch 27: val_loss did not improve from 0.05970\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0573 - accuracy: 0.9839 - val_loss: 0.0640 - val_accuracy: 0.9834 - lr: 0.0010\n",
            "Epoch 28/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.0562 - accuracy: 0.9833\n",
            "Epoch 28: val_loss improved from 0.05970 to 0.05830, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0562 - accuracy: 0.9833 - val_loss: 0.0583 - val_accuracy: 0.9843 - lr: 0.0010\n",
            "Epoch 29/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.0573 - accuracy: 0.9831\n",
            "Epoch 29: val_loss did not improve from 0.05830\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0573 - accuracy: 0.9831 - val_loss: 0.0692 - val_accuracy: 0.9829 - lr: 0.0010\n",
            "Epoch 30/100\n",
            "2185/2189 [============================>.] - ETA: 0s - loss: 0.0554 - accuracy: 0.9839\n",
            "Epoch 30: val_loss improved from 0.05830 to 0.05776, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0555 - accuracy: 0.9839 - val_loss: 0.0578 - val_accuracy: 0.9856 - lr: 0.0010\n",
            "Epoch 31/100\n",
            "2184/2189 [============================>.] - ETA: 0s - loss: 0.0542 - accuracy: 0.9838\n",
            "Epoch 31: val_loss did not improve from 0.05776\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0542 - accuracy: 0.9838 - val_loss: 0.0591 - val_accuracy: 0.9848 - lr: 0.0010\n",
            "Epoch 32/100\n",
            "2181/2189 [============================>.] - ETA: 0s - loss: 0.0546 - accuracy: 0.9841\n",
            "Epoch 32: val_loss did not improve from 0.05776\n",
            "2189/2189 [==============================] - 14s 7ms/step - loss: 0.0547 - accuracy: 0.9841 - val_loss: 0.0595 - val_accuracy: 0.9849 - lr: 0.0010\n",
            "Epoch 33/100\n",
            "2182/2189 [============================>.] - ETA: 0s - loss: 0.0523 - accuracy: 0.9845\n",
            "Epoch 33: val_loss did not improve from 0.05776\n",
            "2189/2189 [==============================] - 14s 7ms/step - loss: 0.0523 - accuracy: 0.9845 - val_loss: 0.0692 - val_accuracy: 0.9834 - lr: 0.0010\n",
            "Epoch 34/100\n",
            "2182/2189 [============================>.] - ETA: 0s - loss: 0.0534 - accuracy: 0.9839\n",
            "Epoch 34: val_loss did not improve from 0.05776\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0534 - accuracy: 0.9839 - val_loss: 0.0670 - val_accuracy: 0.9809 - lr: 0.0010\n",
            "Epoch 35/100\n",
            "2188/2189 [============================>.] - ETA: 0s - loss: 0.0529 - accuracy: 0.9841\n",
            "Epoch 35: val_loss did not improve from 0.05776\n",
            "2189/2189 [==============================] - 14s 7ms/step - loss: 0.0529 - accuracy: 0.9841 - val_loss: 0.0586 - val_accuracy: 0.9846 - lr: 0.0010\n",
            "Epoch 36/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.0520 - accuracy: 0.9851\n",
            "Epoch 36: val_loss improved from 0.05776 to 0.05427, saving model to best_model.h5\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0519 - accuracy: 0.9851 - val_loss: 0.0543 - val_accuracy: 0.9857 - lr: 0.0010\n",
            "Epoch 37/100\n",
            "2182/2189 [============================>.] - ETA: 0s - loss: 0.0514 - accuracy: 0.9852\n",
            "Epoch 37: val_loss did not improve from 0.05427\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0513 - accuracy: 0.9853 - val_loss: 0.0578 - val_accuracy: 0.9849 - lr: 0.0010\n",
            "Epoch 38/100\n",
            "2187/2189 [============================>.] - ETA: 0s - loss: 0.0508 - accuracy: 0.9845\n",
            "Epoch 38: val_loss did not improve from 0.05427\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0508 - accuracy: 0.9845 - val_loss: 0.0604 - val_accuracy: 0.9834 - lr: 0.0010\n",
            "Epoch 39/100\n",
            "2184/2189 [============================>.] - ETA: 0s - loss: 0.0504 - accuracy: 0.9854\n",
            "Epoch 39: val_loss did not improve from 0.05427\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0504 - accuracy: 0.9854 - val_loss: 0.0665 - val_accuracy: 0.9820 - lr: 0.0010\n",
            "Epoch 40/100\n",
            "2183/2189 [============================>.] - ETA: 0s - loss: 0.0494 - accuracy: 0.9853\n",
            "Epoch 40: val_loss did not improve from 0.05427\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0494 - accuracy: 0.9853 - val_loss: 0.0653 - val_accuracy: 0.9827 - lr: 0.0010\n",
            "Epoch 41/100\n",
            "2186/2189 [============================>.] - ETA: 0s - loss: 0.0509 - accuracy: 0.9852\n",
            "Epoch 41: val_loss did not improve from 0.05427\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0508 - accuracy: 0.9852 - val_loss: 0.0548 - val_accuracy: 0.9850 - lr: 0.0010\n",
            "Epoch 42/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0487 - accuracy: 0.9856\n",
            "Epoch 42: val_loss did not improve from 0.05427\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0487 - accuracy: 0.9856 - val_loss: 0.0596 - val_accuracy: 0.9849 - lr: 0.0010\n",
            "Epoch 43/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0482 - accuracy: 0.9860\n",
            "Epoch 43: val_loss did not improve from 0.05427\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0482 - accuracy: 0.9860 - val_loss: 0.0576 - val_accuracy: 0.9854 - lr: 0.0010\n",
            "Epoch 44/100\n",
            "2189/2189 [==============================] - ETA: 0s - loss: 0.0455 - accuracy: 0.9860\n",
            "Epoch 44: val_loss did not improve from 0.05427\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0455 - accuracy: 0.9860 - val_loss: 0.0578 - val_accuracy: 0.9858 - lr: 0.0010\n",
            "Epoch 45/100\n",
            "2183/2189 [============================>.] - ETA: 0s - loss: 0.0463 - accuracy: 0.9862\n",
            "Epoch 45: val_loss did not improve from 0.05427\n",
            "2189/2189 [==============================] - 15s 7ms/step - loss: 0.0465 - accuracy: 0.9862 - val_loss: 0.0615 - val_accuracy: 0.9847 - lr: 0.0010\n",
            "Epoch 46/100\n",
            "2185/2189 [============================>.] - ETA: 0s - loss: 0.0468 - accuracy: 0.9860Restoring model weights from the end of the best epoch: 36.\n",
            "\n",
            "Epoch 46: val_loss did not improve from 0.05427\n",
            "2189/2189 [==============================] - 14s 7ms/step - loss: 0.0468 - accuracy: 0.9860 - val_loss: 0.0676 - val_accuracy: 0.9844 - lr: 0.0010\n",
            "Epoch 46: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Assuming the last column is the label\n",
        "X_test_df = fazeli_mitbih_test_df.iloc[:, :-1].values\n",
        "y_test_df = fazeli_mitbih_test_df.iloc[:, -1].values\n",
        "\n",
        "# Reshape X to fit the Conv1D input requirements\n",
        "X_test_reshaped = X_test_df.reshape((X_test_df.shape[0], X_test_df.shape[1], 1))\n",
        "\n",
        "# Convert y to categorical if your model's output is categorical\n",
        "y_test_categorical = to_categorical(y_test_df)\n",
        "\n",
        "# Evaluate the model on the separate test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test_reshaped, y_test_categorical)\n",
        "print(f\"Test Loss: {test_loss}\")\n",
        "print(f\"Test Accuracy: {test_accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vmNFaTVAtFE",
        "outputId": "678280ab-9f3f-4479-f1c9-b8c07137ce06"
      },
      "id": "9vmNFaTVAtFE",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "685/685 [==============================] - 2s 3ms/step - loss: 0.0649 - accuracy: 0.9846\n",
            "Test Loss: 0.06490693241357803\n",
            "Test Accuracy: 0.9845605492591858\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GICFqu-CFd4R"
      },
      "id": "GICFqu-CFd4R",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python [conda env:tf-gpu] *",
      "language": "python",
      "name": "conda-env-tf-gpu-py"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}