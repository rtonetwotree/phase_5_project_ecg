{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a00172b-9894-4971-a537-441334e1f38d",
   "metadata": {},
   "source": [
    "### First Models\n",
    "\n",
    "LogReg *baseline model*\n",
    "\n",
    "Other Models *more advanced but still not tuned*\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96435299-050b-4010-b57c-cc490b83b705",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "\n",
    "# If you need to plot or visualize data later on\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# For any data preprocessing or manipulation\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Depending on the models you plan to use\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38da3325-d76d-421e-94d0-0596c6b95d3b",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37dbff3e-7b6b-4798-9190-3d0180925068",
   "metadata": {},
   "outputs": [],
   "source": [
    "fazeli_mitbih_train_df = pd.read_csv('../data/mitbih_train.csv', header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "74aed28a-031c-4298-a7f8-3d01d46e93be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    72471\n",
       "4.0     6431\n",
       "2.0     5788\n",
       "1.0     2223\n",
       "3.0      641\n",
       "Name: 187, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_187 = fazeli_mitbih_train_df.iloc[:, 187]\n",
    "column_187.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee19804-7f3c-4139-8068-df2c0700db04",
   "metadata": {},
   "source": [
    "## Comprehensive Feature Extraction\n",
    "\n",
    "using tsfresh time series comprehensive feature extraction package"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e950b2da-a4ef-4a60-b0bf-c3be621ba4da",
   "metadata": {},
   "source": [
    "### Next cell takes 15-30 min to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb38587e-4ec4-449d-80dd-366aa28a7e83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Feature Extraction: 100%|███████████████████████| 35/35 [01:07<00:00,  1.93s/it]\n",
      "Feature Extraction: 100%|███████████████████████| 35/35 [01:09<00:00,  1.99s/it]\n",
      "Feature Extraction: 100%|███████████████████████| 35/35 [01:12<00:00,  2.07s/it]\n",
      "Feature Extraction: 100%|███████████████████████| 35/35 [01:13<00:00,  2.09s/it]\n",
      "Feature Extraction: 100%|███████████████████████| 35/35 [01:14<00:00,  2.12s/it]\n",
      "Feature Extraction: 100%|███████████████████████| 35/35 [01:17<00:00,  2.23s/it]\n",
      "Feature Extraction: 100%|███████████████████████| 35/35 [01:29<00:00,  2.55s/it]\n",
      "Feature Extraction: 100%|███████████████████████| 35/35 [01:32<00:00,  2.63s/it]\n",
      "Feature Extraction: 100%|███████████████████████| 35/35 [01:06<00:00,  1.89s/it]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.feature_extraction import ComprehensiveFCParameters\n",
    "\n",
    "# Load your dataset\n",
    "fazeli_mitbih_train_df = pd.read_csv('../data/mitbih_train.csv', header=None)\n",
    "\n",
    "# Assign a unique ID to each row and separate the target variable\n",
    "fazeli_mitbih_train_df['id'] = range(len(fazeli_mitbih_train_df))\n",
    "target_series = fazeli_mitbih_train_df[187]\n",
    "\n",
    "# Keep only features and the unique ID for feature extraction\n",
    "fazeli_mitbih_train_df_features_only = fazeli_mitbih_train_df.drop(columns=[187])\n",
    "\n",
    "# Convert to long format, preserving the 'id' for direct mapping\n",
    "long_df = fazeli_mitbih_train_df_features_only.melt(id_vars='id', var_name='time', value_name='amplitude')\n",
    "\n",
    "# Define feature extraction settings\n",
    "extraction_settings = ComprehensiveFCParameters()\n",
    "\n",
    "# Incremental extraction setup\n",
    "unique_ids = long_df['id'].unique()\n",
    "subset_size = 10000  # Adjust based on your dataset size and memory constraints\n",
    "extracted_features_list = []\n",
    "\n",
    "for i in range(0, len(unique_ids), subset_size):\n",
    "    subset_ids = unique_ids[i:i+subset_size]\n",
    "    subset_df = long_df[long_df['id'].isin(subset_ids)]\n",
    "    \n",
    "    # Extract features for this subset\n",
    "    subset_features = extract_features(subset_df, column_id='id', column_sort='time',\n",
    "                                       default_fc_parameters=extraction_settings, n_jobs=7)\n",
    "    extracted_features_list.append(subset_features)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5ceb8dc3-bb1a-4fc1-8789-1b8cc965c9b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   label\n",
      "0    0.0\n",
      "1    0.0\n",
      "2    0.0\n",
      "3    0.0\n",
      "4    0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Combine extracted features from all subsets\n",
    "extracted_features = pd.concat(extracted_features_list)\n",
    "\n",
    "# Re-associate the target labels using the 'id' column\n",
    "# This step correctly maps the original labels to the extracted features based on 'id'\n",
    "extracted_features['label'] = extracted_features.index.map(lambda idx: target_series.loc[idx])\n",
    "\n",
    "# Verify the re-association of labels\n",
    "print(extracted_features[['label']].head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58082168-ea63-41ed-92ca-4a2a80362104",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    72471\n",
       "4.0     6431\n",
       "2.0     5788\n",
       "1.0     2223\n",
       "3.0      641\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_187_extracted = extracted_features['label']\n",
    "column_187_extracted.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2dadb1-d85e-471a-9e3b-1c9914d0e1ec",
   "metadata": {},
   "source": [
    "RandomForestClassifier?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7c62a9e-4a10-42fe-ab0e-f70e12238336",
   "metadata": {},
   "source": [
    "## Set X and y from extracted features, Perform train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08955da9-01b4-4570-98af-fd2227d80f70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting X and y from my extracted features\n",
    "X = extracted_features.drop('label', axis=1)\n",
    "y = extracted_features['label']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3376e4c2-e6a3-41fc-8edd-3580bf98081c",
   "metadata": {},
   "source": [
    "# Working Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43d4343d-3a69-4660-877d-ea8c54f72c80",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Conv1D, GlobalAveragePooling1D, Dense\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming your input shape is (timesteps, features)\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv1D, GlobalAveragePooling1D, Dense\n",
    "\n",
    "# Assuming your input shape is (timesteps, features)\n",
    "input_shape = (128, 1)  # Example input shape (128 timesteps, 1 feature)\n",
    "\n",
    "model = Sequential([\n",
    "    Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
    "    GlobalAveragePooling1D(),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45829da9-3c91-460e-a034-8676ac0377cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
